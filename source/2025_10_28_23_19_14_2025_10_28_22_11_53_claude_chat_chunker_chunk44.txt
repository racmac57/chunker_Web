Args:
        data: Conversations data (dict with 'conversations' key or list of conversations)
        projects: Projects data (optional)
        merge_to_files: Whether to merge file/attachment references
        keep_invalid: Whether to keep invalid/malformed messages
        
    Returns:
        Processed data
    """
    # Handle both formats: {"conversations": [...]} and [...]
    if isinstance(data, list):
        conversations = data
        is_list_format = True
    elif isinstance(data, dict) and 'conversations' in data:
        conversations = data['conversations']
        is_list_format = False
    else:
        # No conversations found, return as-is
        return data
    
    # Process each conversation
    for conv in conversations:
        # Add model field if missing (required by osteele viewer)
        if 'model' not in conv:
            conv['model'] = conv.get('model_slug', 'claude-sonnet-3-5-20241022')  # Use common default
        
        if 'chat_messages' in conv:
            processed_messages = []
            for msg_idx, msg in enumerate(conv['chat_messages']):
                try:
                    # Add index if missing (required by osteele viewer)
                    if 'index' not in msg:
                        msg['index'] = msg_idx
                    
                    # Add model_slug if missing (required by osteele viewer)
                    if 'model_slug' not in msg:
                        msg['model_slug'] = conv.get('model', 'claude-sonnet-3-5-20241022')
                    
                    # Add content array if missing (CRITICAL for osteele viewer)
                    if 'content' not in msg:
                        # Create basic text content from the text field
                        msg_text = msg.get('text', '')
                        msg['content'] = [{'type': 'text', 'text': msg_text}]
                    
                    if merge_to_files:
                        # Pass message timestamp for file objects (required by osteele viewer)
                        msg_timestamp = msg.get('created_at') or msg.get('updated_at')
                        msg = merge_file_references(msg, msg_timestamp)
                    processed_messages.append(msg)
                except Exception as e:
                    if keep_invalid:
                        logging.warning(f"Invalid message kept: {e}")
                        processed_messages.append(msg)
                    else:
                        logging.debug(f"Skipped invalid message: {e}")
            
            conv['chat_messages'] = processed_messages
    
    # Reconstruct data in original format
    if is_list_format:
        result = conversations
    else:
        data['conversations'] = conversations
        result = data
    
    # Link projects if provided
    if projects:
        result = link_projects(result, projects)
    
    return result


def process_json_streaming(
    input_file: Path,
    output_file: Path,
    projects: Optional[Dict[str, Any]] = None,
    pretty: bool = False,
    merge_to_files: bool = True,
    keep_invalid: bool = False
) -> None:
    """
    Process JSON file using streaming (requires ijson). Args:
        input_file: Input JSON file path
        output_file: Output JSON file path
        projects: Projects data (optional)
        pretty: Whether to pretty-print JSON
        merge_to_files: Whether to merge file/attachment references
        keep_invalid: Whether to keep invalid messages
    """
    if not HAS_IJSON:
        raise ImportError("ijson is required for streaming mode. Install with: pip install ijson")
    
    logging.info(f"Streaming from {input_file} to {output_file}")
    
    # For simplicity, fall back to non-streaming for now
    # Full streaming implementation would require incremental JSON writing
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    data = process_conversation_data(data, projects, merge_to_files, keep_invalid)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        if pretty:
            json.dump(data, f, indent=2, ensure_ascii=False)
        else:
            json.dump(data, f, ensure_ascii=False)


def process_json_file(
    input_file: Path,
    output_file: Path,
    projects: Optional[Dict[str, Any]] = None,
    pretty: bool = False,
    stream: bool = False,
    merge_to_files: bool = True,
    keep_invalid: bool = False
) -> None:
    """
    Process a JSON conversation file. Args:
        input_file: Input JSON file path
        output_file: Output JSON file path
        projects: Projects data (optional)
        pretty: Whether to pretty-print JSON
        stream: Whether to use streaming mode
        merge_to_files: Whether to merge file/attachment references
        keep_invalid: Whether to keep invalid messages
    """
    if stream:
        process_json_streaming(input_file, output_file, projects, pretty, merge_to_files, keep_invalid)
        return
    
    logging.info(f"Processing {input_file}")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    data = process_conversation_data(data, projects, merge_to_files, keep_invalid)
    
    logging.info(f"Writing to {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        if pretty:
            json.dump(data, f, indent=2, ensure_ascii=False)
        else:
            json.dump(data, f, ensure_ascii=False)


def process_zip_file(
    input_file: Path,
    output_file: Path,
    projects_data: Optional[Dict[str, Any]] = None,
    pretty: bool = False,
    stream: bool = False,
    merge_to_files: bool = True,
    keep_invalid: bool = False,
    no_backup: bool = False
) -> None:
    """
    Process a ZIP archive containing conversations.json. Args:
        input_file: Input ZIP file path
        output_file: Output ZIP file path
        projects_data: Projects data (optional, if not in ZIP)
        pretty: Whether to pretty-print JSON
        stream: Whether to use streaming mode
        merge_to_files: Whether to merge file/attachment references
        keep_invalid: Whether to keep invalid messages
        no_backup: Skip creating backup of original ZIP
    """
    logging.info(f"Processing ZIP: {input_file}")
    
    # Create backup unless disabled
    if not no_backup:
        backup_path = input_file.with_suffix(input_file.suffix + '.bak')
        import shutil
        shutil.copy2(input_file, backup_path)
        logging.info(f"Backup created: {backup_path}")
    
    conversations_data = None
    projects_from_zip = None
    other_files = {}
    
    # Read ZIP contents
    with zipfile.ZipFile(input_file, 'r') as zin:
        for info in zin.infolist():
            if info.filename == 'conversations.json':
                with zin.open(info) as f:
                    conversations_data = json.load(f)
            elif info.filename == 'projects.json':
                with zin.open(info) as f:
                    projects_from_zip = json.load(f)
            else:
                # Preserve other files (metadata, attachments, etc.) other_files[info.filename] = (zin.read(info), info)
    
    if conversations_data is None:
        raise ValueError("No conversations.json found in ZIP")
    
    # Use projects from ZIP if available, otherwise use provided
    projects = projects_from_zip or projects_data
    
    # Process conversations
    conversations_data = process_conversation_data(
        conversations_data, projects, merge_to_files, keep_invalid
    )
    
    # Write output ZIP
    logging.info(f"Writing to {output_file}")
    with zipfile.ZipFile(output_file, 'w', zipfile.ZIP_DEFLATED) as zout:
        # Write processed conversations
        conversations_json = json.dumps(
            conversations_data,
            indent=2 if pretty else None,
            ensure_ascii=False
        )
        zout.writestr('conversations.json', conversations_json)
        
        # Preserve projects.json if it existed
        if projects_from_zip:
            projects_json = json.dumps(
                projects_from_zip,
                indent=2 if pretty else None,
                ensure_ascii=False
            )
            zout.writestr('projects.json', projects_json)
        
        # Preserve other files with original metadata
        for filename, (data, info) in other_files.items():
            zinfo = zipfile.ZipInfo(filename, info.date_time)
            zinfo.compress_type = info.compress_type
            zinfo.external_attr = info.external_attr
            zout.writestr(zinfo, data)


def find_projects_file(input_file: Path) -> Optional[Path]:
    """
    Try to find projects.json next to the input file. Args:
        input_file: Input file path
        
    Returns:
        Path to projects.json if found, None otherwise
    """
    projects_path = input_file.parent / 'projects.json'
    if projects_path.exists():
        logging.debug(f"Found projects file: {projects_path}")
        return projects_path
    return None


def load_projects(projects_path: Optional[Path]) -> Optional[Dict[str, Any]]:
    """
    Load projects.json if path provided and exists. Args:
        projects_path: Path to projects.json
        
    Returns:
        Projects data dictionary or None
    """
    if projects_path and projects_path.exists():
        logging.info(f"Loading projects from {projects_path}")
        with open(projects_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def generate_report(
    input_file: Path,
    output_file: Path,
    report_path: Path,
    success: bool,
    error: Optional[str] = None
) -> None:
    """
    Generate a CSV report of the processing. Args:
        input_file: Input file path
        output_file: Output file path
        report_path: Report output path
        success: Whether processing succeeded
        error: Error message if failed
    """
    import csv
    from datetime import datetime
    
    with open(report_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['timestamp', 'input', 'output', 'success', 'error'])
        writer.writerow([
            datetime.now().isoformat(),
            str(input_file),
            str(output_file) if success else '',
            'yes' if success else 'no',
            error or ''
        ])
    
    logging.info(f"Report written to {report_path}")


def process_file(
    input_path: Union[str, Path],
    output_path: Union[str, Path],
    projects_path: Optional[Union[str, Path]] = None,
    zip_output: bool = False,
    stream: bool = False,
    pretty: bool = False,
    strict: bool = False,
    verbose: bool = False,
    quiet: bool = False,
    no_backup: bool = False,
    no_merge_to_files: bool = False,
    keep_invalid: bool = False
) -> int:
    """
    Main processing function. Args:
        input_path: Input file path (JSON or ZIP)
        output_path: Output file path
        projects_path: Optional projects.json path
        zip_output: Force ZIP output
        stream: Use streaming mode
        pretty: Pretty-print JSON
        strict: Strict mode (fail on any error)
        verbose: Verbose logging
        quiet: Quiet mode (errors only)
        no_backup: Don't create backup of ZIP files
        no_merge_to_files: Don't merge file/attachment references
        keep_invalid: Keep invalid messages instead of skipping
        
    Returns:
        Exit code (0 for success, 1 for failure)
    """
    setup_logging(verbose, quiet)
    
    input_file = Path(input_path)
    output_file = Path(output_path)
    
    if not input_file.exists():
        logging.error(f"Input file not found: {input_file}")
        return 1
    
    # Auto-detect projects.json if not provided
    if projects_path:
        projects_file = Path(projects_path)
    else:
        projects_file = find_projects_file(input_file)
    
    projects_data = load_projects(projects_file)
    
    # Determine report path
    report_path = output_file.with_name(output_file.stem + '_report.csv')
    
    try:
        # Process based on input type
        if input_file.suffix.lower() == '.zip':
            if zip_output or output_file.suffix.lower() == '.zip':
                # ZIP to ZIP
                process_zip_file(
                    input_file, output_file, projects_data,
                    pretty, stream, not no_merge_to_files, keep_invalid, no_backup
                )
            else:
                # ZIP to JSON (extract conversations.json)
                with zipfile.ZipFile(input_file, 'r') as zin:
                    if 'conversations.json' not in zin.namelist():
                        raise ValueError("No conversations.json in ZIP")
                    
                    with zin.open('conversations.json') as f:
                        data = json.load(f)
                    
                    # Check for projects in ZIP
                    if 'projects.json' in zin.namelist() and not projects_data:
                        with zin.open('projects.json') as f:
                            projects_data = json.load(f)
                
                data = process_conversation_data(data, projects_data, not no_merge_to_files, keep_invalid)
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    if pretty:
                        json.dump(data, f, indent=2, ensure_ascii=False)
                    else:
                        json.dump(data, f, ensure_ascii=False)
        else:
            # JSON input
            if zip_output or output_file.suffix.lower() == '.zip':
                # JSON to ZIP
                process_json_file(
                    input_file, output_file.with_suffix('.json'),
                    projects_data, pretty, stream, not no_merge_to_files, keep_invalid
                )
                # Create ZIP with the processed JSON
                with zipfile.ZipFile(output_file, 'w', zipfile.ZIP_DEFLATED) as zout:
                    with open(output_file.with_suffix('.json'), 'r') as f:
                        zout.writestr('conversations.json', f.read())
                    if projects_data:
                        projects_json = json.dumps(projects_data, indent=2 if pretty else None)
                        zout.writestr('projects.json', projects_json)
                # Clean up temp JSON
                output_file.with_suffix('.json').unlink()
            else:
                # JSON to JSON
                process_json_file(
                    input_file, output_file, projects_data,
                    pretty, stream, not no_merge_to_files, keep_invalid
                )
        
        logging.info("Processing complete!") generate_report(input_file, output_file, report_path, True)
        return 0
        
    except Exception as e:
        logging.error(f"Processing failed: {e}")
        if strict:
            raise
        generate_report(input_file, output_file, report_path, False, str(e))
        return 1


def main() -> int:
    """Main CLI entry point.""" parser = argparse.ArgumentParser(
        description='Normalize Claude.ai conversation exports for compatibility. ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s conversations.json -o fixed.json --pretty
  %(prog)s export.zip -o patched.zip --zip-output --stream
  %(prog)s --gui
        """
    )
    
    parser.add_argument('--version', action='version', version=f'%(prog)s {__version__}')
    parser.add_argument('input', nargs='? ', help='Input file (JSON or ZIP)')
    parser.add_argument('-o', '--output', help='Output file path')
    parser.add_argument('-p', '--projects', help='Path to projects.json (auto-detected if not specified)')
    parser.add_argument('--zip-output', action='store_true', help='Force ZIP output')
    parser.add_argument('--stream', action='store_true', help='Use streaming mode for large files (requires ijson)')
    parser.add_argument('--pretty', action='store_true', help='Pretty-print JSON output')
    parser.add_argument('--strict', action='store_true', help='Strict mode: fail on any error')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    parser.add_argument('-q', '--quiet', action='store_true', help='Quiet mode (errors only)')
    parser.add_argument('--no-backup', action='store_true', help='Do not create backup of ZIP files')
    parser.add_argument('--no-merge-to-files', action='store_true', help='Do not merge file/attachment references')
    parser.add_argument('--keep-invalid', action='store_true', help='Keep invalid messages instead of skipping')
    parser.add_argument('--gui', action='store_true', help='Launch a simple Tkinter UI (optional)')
    parser.add_argument('--version', action='version', version=f'%(prog)s {__version__}')
    
    args = parser.parse_args()
    
    # GUI mode
    if args.gui:
        try:
            from gui import launch_gui
            launch_gui()
            return 0
        except ImportError as e:
            print(f"ERROR: GUI not available: {e}", file=sys.stderr)
            print("Tkinter is required for GUI mode (usually included with Python)", file=sys.stderr)
            return 1
        except Exception as e:
            print(f"ERROR: GUI failed to launch: {e}", file=sys.stderr)
            return 1
    
    # CLI mode - require input and output
    if not args.input:
        parser.error("the following arguments are required: input (or use --gui)")
    
    if not args.output:
        parser.error("the following arguments are required: -o/--output (or use --gui)")
    
    return process_file(
        args.input,
        args.output,
        args.projects,
        args.zip_output,
        args.stream,
        args.pretty,
        args.strict,
        args.verbose,
        args.quiet,
        args.no_backup,
        args.no_merge_to_files,
        args.keep_invalid
    )


if __name__ == "__main__":
    sys.exit(main())

```

Good! Now let's enhance the GUI with the "Open Output" button:

Good! The `_suggest_output_path` is already there. Now let's check if we need to add `subprocess` and `sys` imports:

```python
#!/usr/bin/env python3
"""
Tkinter GUI for ClaudeExportFixer. Provides a simple graphical interface for processing Claude conversation exports.
""" import logging
import os
import platform
import queue
import subprocess
import sys
import threading
import tkinter as tk
from pathlib import Path
from tkinter import filedialog, messagebox, ttk
from typing import Optional

from patch_conversations import __version__, process_file


def _suggest_output_path(input_path: str, zip_output: bool) -> str:
    """
    Generate output path suggestion based on input path and zip_output flag. Args:
        input_path: Input file path
        zip_output: Whether ZIP output is requested
        
    Returns:
        Suggested output path with _patched suffix
    """
    input_file = Path(input_path)
    ext = ".zip" if zip_output else ".json"
    suggested = input_file.parent / (input_file.stem + "_patched" + ext)
    return str(suggested)


class QueueHandler(logging.Handler):
    """Custom logging handler that sends messages to a queue.""" def __init__(self, log_queue: queue.Queue):
        super().__init__()
        self.log_queue = log_queue
    
    def emit(self, record: logging.LogRecord) -> None:
        self.log_queue.put(self.format(record))


class ClaudeExportFixerGUI:
    """Main GUI application class.""" def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title(f"ClaudeExportFixer v{__version__}")
        self.root.geometry("800x700")
        self.root.resizable(True, True)
        
        # Variables
        self.input_path = tk.StringVar()
        self.output_path = tk.StringVar()
        self.projects_path = tk.StringVar()
        
        self.zip_output_var = tk.BooleanVar(value=False)
        self.stream_var = tk.BooleanVar(value=False)
        self.pretty_var = tk.BooleanVar(value=True)  # Default ON
        self.strict_var = tk.BooleanVar(value=False)
        self.quiet_var = tk.BooleanVar(value=False)
        self.verbose_var = tk.BooleanVar(value=False)
        self.no_backup_var = tk.BooleanVar(value=False)
        self.no_merge_to_files_var = tk.BooleanVar(value=False)
        self.keep_invalid_var = tk.BooleanVar(value=False)
        
        self.processing = False
        self.last_output_path: Optional[str] = None
        self.log_queue: queue.Queue = queue.Queue()
        
        self.setup_ui()
        self.setup_logging()
        self.poll_log_queue()
    
    def setup_ui(self) -> None:
        """Set up the user interface.""" # Main frame with padding
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        row = 0
        
        # Input file section
        ttk.Label(main_frame, text="Input File:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Entry(main_frame, textvariable=self.input_path, width=50).grid(
            row=row, column=1, sticky=(tk.W, tk.E), pady=5, padx=5
        )
        ttk.Button(main_frame, text="Browse...", command=self.browse_input).grid(
            row=row, column=2, pady=5
        )
        row += 1
        
        # Output file section
        ttk.Label(main_frame, text="Output File:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Entry(main_frame, textvariable=self.output_path, width=50).grid(
            row=row, column=1, sticky=(tk.W, tk.E), pady=5, padx=5
        )
        ttk.Button(main_frame, text="Save as...", command=self.browse_output).grid(
            row=row, column=2, pady=5
        )
        row += 1
        
        # Projects file section (read-only, auto-detected)
        ttk.Label(main_frame, text="Projects File:").grid(row=row, column=0, sticky=tk.W, pady=5)
        projects_entry = ttk.Entry(main_frame, textvariable=self.projects_path, width=50, state='readonly')
        projects_entry.grid(row=row, column=1, sticky=(tk.W, tk.E), pady=5, padx=5)
        ttk.Label(main_frame, text="(auto-detected)").grid(row=row, column=2, pady=5)
        row += 1
        
        # Separator
        ttk.Separator(main_frame, orient='horizontal').grid(
            row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=10
        )
        row += 1
        
        # Options section
        ttk.Label(main_frame, text="Options:", font=('TkDefaultFont', 10, 'bold')).grid(
            row=row, column=0, columnspan=3, sticky=tk.W, pady=5
        )
        row += 1
        
        # Create two-column layout for checkboxes
        options_frame = ttk.Frame(main_frame)
        options_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # Left column
        left_col = ttk.Frame(options_frame)
        left_col.grid(row=0, column=0, sticky=(tk.W, tk.N), padx=(0, 20))
        
        ttk.Checkbutton(left_col, text="ZIP output", variable=self.zip_output_var,
                       command=self.on_zip_output_changed).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(left_col, text="Stream (large files)", variable=self.stream_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(left_col, text="Pretty print", variable=self.pretty_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(left_col, text="Strict mode", variable=self.strict_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(left_col, text="No backup (ZIP)", variable=self.no_backup_var).pack(anchor=tk.W, pady=2)
        
        # Right column
        right_col = ttk.Frame(options_frame)
        right_col.grid(row=0, column=1, sticky=(tk.W, tk.N))
        
        ttk.Checkbutton(right_col, text="Verbose logging", variable=self.verbose_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(right_col, text="Quiet mode", variable=self.quiet_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(right_col, text="No merge to files", variable=self.no_merge_to_files_var).pack(anchor=tk.W, pady=2)
        ttk.Checkbutton(right_col, text="Keep invalid messages", variable=self.keep_invalid_var).pack(anchor=tk.W, pady=2)
        
        row += 1
        
        # Separator
        ttk.Separator(main_frame, orient='horizontal').grid(
            row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=10
        )
        row += 1
        
        # Buttons section
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=row, column=0, columnspan=3, pady=10)
        
        self.run_button = ttk.Button(button_frame, text="Run", command=self.run_processing, width=15)
        self.run_button.pack(side=tk.LEFT, padx=5)
        
        self.open_output_button = ttk.Button(
            button_frame, text="Open Output", command=self.open_output, width=15, state='disabled'
        )
        self.open_output_button.pack(side=tk.LEFT, padx=5)
        
        ttk.Button(button_frame, text="Cancel", command=self.root.quit, width=15).pack(side=tk.LEFT, padx=5)
        
        row += 1
        
        # Progress bar
        self.progress = ttk.Progressbar(main_frame, mode='indeterminate')
        self.progress.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        row += 1
        
        # Log output section
        ttk.Label(main_frame, text="Log Output:", font=('TkDefaultFont', 10, 'bold')).grid(
            row=row, column=0, columnspan=3, sticky=tk.W, pady=(10, 5)
        )
        row += 1
        
        # Text area with scrollbar
        log_frame = ttk.Frame(main_frame)
        log_frame.grid(row=row, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        main_frame.rowconfigure(row, weight=1)
        
        self.log_text = tk.Text(log_frame, height=15, width=80, wrap=tk.WORD, state='disabled')
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar = ttk.Scrollbar(log_frame, orient='vertical', command=self.log_text.yview)
        scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        self.log_text['yscrollcommand'] = scrollbar.set
        
        # Update button states
        self.update_button_states()
    
    def setup_logging(self) -> None:
        """Set up logging to queue.""" self.queue_handler = QueueHandler(self.log_queue)
        formatter = logging.Formatter('%(levelname)s: %(message)s')
        self.queue_handler.setFormatter(formatter)
        
        # Get root logger and add our handler
        logger = logging.getLogger()
        logger.addHandler(self.queue_handler)
        logger.setLevel(logging.INFO)
    
    def poll_log_queue(self) -> None:
        """Poll the log queue and update the text widget.""" while True:
            try:
                message = self.log_queue.get_nowait()
                self.append_log(message + '\n')
            except queue.Empty:
                break
        
        # Schedule next poll
        self.root.after(50, self.poll_log_queue)
    
    def append_log(self, message: str) -> None:
        """Append message to log text area.""" self.log_text.config(state='normal')
        self.log_text.insert(tk.END, message)
        self.log_text.see(tk.END)
        self.log_text.config(state='disabled')
    
    def browse_input(self) -> None:
        """Open file dialog for input file.""" filename = filedialog.askopenfilename(
            title="Select Input File",
            filetypes=[
                ("Supported files", "*.json *.zip"),
                ("JSON files", "*.json"),
                ("ZIP files", "*.zip"),
                ("All files", "*. *")
            ]
        )
        
        if filename:
            self.input_path.set(filename)
            self.update_projects_path()
            self.suggest_output_path()
            self.update_button_states()
    
    def browse_output(self) -> None:
        """Open file dialog for output file.""" # Determine default extension based on zip_output checkbox
        if self.zip_output_var.get():
            default_ext = ".zip"
            filetypes = [("ZIP files", "*.zip"), ("All files", "*. *")]
        else:
            default_ext = ".json"
            filetypes = [("JSON files", "*.json"), ("All files", "*. *")]
        
        # Get initial filename
        initial_file = ""
        if self.input_path.get():
            input_path = Path(self.input_path.get())
            initial_file = str(input_path.stem + "_patched" + default_ext)
        
        filename = filedialog.asksaveasfilename(
            title="Save Output File",
            initialfile=initial_file,
            defaultextension=default_ext,
            filetypes=filetypes
        )
        
        if filename:
            self.output_path.set(filename)
            self.update_button_states()
    
    def update_projects_path(self) -> None:
        """Auto-detect projects.json next to input file.""" if not self.input_path.get():
            self.projects_path.set("No input file selected")
            return
        
        input_file = Path(self.input_path.get())
        projects_file = input_file.parent / 'projects.json'
        
        if projects_file.exists():
            self.projects_path.set(str(projects_file))
        else:
            self.projects_path.set("No projects.json found")
    
    def suggest_output_path(self) -> None:
        """Suggest output path based on input and settings."""