TimeOfDay	Monday_100 block of Main St	Monday_200 block of Elm Ave	Tuesday_100 block of Main St	... Early Morning	4	2	0	
Morning	1	0	5	
Afternoon	0	0	0	
...	...	...	...	

2. Final Python Script (ArcPy + pandas)
python
Copy
Edit
import arcpy
import pandas as pd
import re

# Set workspace and CAD layer
arcpy.env.workspace = "YOUR_PROJECT_GDB_PATH"  # Replace with your GDB path
cad_layer = "YOUR_PORTAL_LAYER_NAME"  # Replace with your Portal layer name

# Export CAD layer to feature class (if not already)
output_fc = "cad_calls_fc"
if not arcpy.Exists(output_fc):
    arcpy.conversion.FeatureClassToFeatureClass(cad_layer, arcpy.env.workspace, output_fc)

# Convert to pandas DataFrame
fields = ['CallDate', 'FullAddress']
df = pd.DataFrame(arcpy.da.TableToNumPyArray(output_fc, fields))

# Parse datetime and extract components
df['CallDate'] = pd.to_datetime(df['CallDate'], errors='coerce')
df = df.dropna(subset=['CallDate'])
df['DayOfWeek'] = df['CallDate'].dt.day_name()
df['Hour'] = df['CallDate'].dt.hour

# Time of day categorization
def categorize_time(hour):
    if 0 <= hour <= 3:
        return 'Early Morning'
    elif 4 <= hour <= 7:
        return 'Morning'
    elif 8 <= hour <= 10:
        return 'Rush Hour'
    elif 11 <= hour <= 15:
        return 'Afternoon'
    elif 16 <= hour <= 19:
        return 'Evening'
    else:
        return 'Night'

df['TimeOfDay'] = df['Hour'].apply(categorize_time)

# Parse address block
def parse_address(address):
    match = re.match(r"(\d+)\s+(. *)", address)
    if match:
        num = int(match.group(1))
        street = match.group(2)
        block = f"{(num // 100) * 100} block of {street}"
        return pd.Series([num, street, block])
    return pd.Series([None, None, None])

df[['AddressNumber', 'StreetName', 'AddressBlock']] = df['FullAddress'].apply(parse_address)

# Drop rows with missing block
df = df.dropna(subset=['AddressBlock'])

# === Flat summary table ===
flat_summary = df.groupby(['TimeOfDay', 'DayOfWeek', 'AddressBlock']).size().reset_index(name='Count')
flat_summary.to_csv("flat_summary.csv", index=False)

# === Pivot table summary ===
pivot_summary = pd.pivot_table(
    df,
    index='TimeOfDay',
    columns=['DayOfWeek', 'AddressBlock'],
    aggfunc='size',
    fill_value=0
)

# Flatten multi-index columns for easier export
pivot_summary.columns = ['_'.join(col).replace(' ', '_') for col in pivot_summary.columns]
pivot_summary.reset_index(inplace=True)
pivot_summary.to_csv("pivot_summary.csv", index=False)
Outputs:
flat_summary.csv: Detailed counts by time of day, day of week, and block. pivot_summary.csv: Wide-format cross-tab of time by day + location. Would you like me to also show how to convert either output into a table inside a File Geodatabase? Provide Feedback | View Changes | Contribute. You said:
What if I wanted to take I wanted the python script to run in conjunction with another python script I have for taking that same data and putting symbology on a map. I‚Äôm having layouts being automatically exported to a folder. Would it be possible to have these tables exported asJPEG so I could add them to a PowerPoint slide? I have report that‚Äôs due every Tuesday. This will be very helpful. ChatGPT said:
Absolutely ‚Äî you can integrate this tabular summary directly into your automated map export workflow. Since you‚Äôre already exporting layouts as JPEGs, you can also render the summary tables (flat or pivot) as JPEG images and save them to the same folder, ready to drop into PowerPoint. Here‚Äôs a solution outline followed by updated script examples. How to Include Summary Tables as JPEGs in Your Workflow
Use matplotlib to render the pandas DataFrame as a table. Export the rendered table as a .jpg (or .png) image. Run this logic after your existing symbology/map export logic, or integrate it into the same script. Updated Python Script: Export Summary Tables as JPEGs
Add this snippet at the end of the previous script:

python
Copy
Edit
import matplotlib.pyplot as plt

def export_table_as_image(dataframe, image_path, title=None):
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.axis('off')
    table = ax.table(cellText=dataframe.values,
                     colLabels=dataframe.columns,
                     loc='center',
                     cellLoc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.2)
    
    if title:
        plt.title(title, fontsize=14, pad=20)

    plt.tight_layout()
    plt.savefig(image_path, dpi=300, bbox_inches='tight')
    plt.close()

# Export tables as JPEG images for PowerPoint
export_table_as_image(flat_summary.head(20), 'flat_summary.jpg', title='Incident Summary - Flat Table')
export_table_as_image(pivot_summary.head(10), 'pivot_summary.jpg', title='Incident Summary - Pivot Table')
Tip: Use .head(20) or .head(10) to avoid overly large tables; adjust as needed. Integration Options
You can integrate this directly into your layout export script like this:

python
Copy
Edit
# After exporting map layouts
arcpy.mp.ArcGISProject("CURRENT")
# Your layout export logic here...
# Then run the summary table logic
Or you can call both scripts from a master .py or .bat file using subprocess or scheduling with Windows Task Scheduler. Automated Reporting Workflow Suggestions:
Folder structure: Create folders like /Reports/YYYY-MM-DD/ for each week's output. Exported content:

Map_Monday.jpg, Map_Tuesday.jpg, ...

flat_summary.jpg

pivot_summary.jpg

flat_summary.csv

PowerPoint: Use a template where the table image is inserted in a fixed location each week. Automation trigger: Schedule the script to run every Monday night or early Tuesday with Windows Task Scheduler or Task Sequence. Would you like a sample script that combines your layout export and table rendering into one unified script? Provide Feedback | View Changes | Contribute. 2/2












ChatGPT can make mistakes. Check important info. --- Conversation 6: @_ArcGIS Pro SCRPA Query Filtering and Symbology ---
Skip to content
Chat history



New project
Previous 7 Days



















Previous 30 Days
































You said:
ArcGISProTempletQuestion.txt
Document
7Day 28Day Cycle 20250414

Unable to display visualization
review the attached file from a earlier conversation for context. Updated Information:
I confirmed that the data from the portal is a hosted feature layer. Knowing this when using Definition Queries is contain text case sensitive? Can you write a code that will filter the data for the following:
7-Day Cycle
Call Date: is on or after, start of current, 7_Day_Start
Call Date: is on or before, 7_Day_End	
Disposition: contains the text, report (if case sensitivity is not an issue)
Call Type: contains the text, one of each of the above incidents, (if case sensitivity is not an issue)
Call Types Contain:
1. Vehicle Theft
2. Commercial, Residence
3. Robbery
4. Sexual
5. Auto

28-Day Cycle
Call Date: is on or after, start of current, 28_Day_Start
Call Date: is on or before, 28_Day_End	
Disposition: contains the text, report (if case sensitivity is not an issue)
Call Type: contains the text, one of each of the above incidents, (if case sensitivity is not an issue)
Call Types Contain:
1. Vehicle Theft
2. Commercial, Residence
3. Robbery
4. Sexual
5. Auto

Year to Date Denifition Query:
Call Date: is on or after, 12/31/2024	
Disposition: contains the text, report (if case sensitivity is not an issue)
Call Type: contains the text, one of each of the above incidents, (if case sensitivity is not an issue)
Call Types Contain:
1. Vehicle Theft
2. Commercial, Residence
3. Robbery
4. Sexual
5. Auto

7-Day Symbology: Square 3
28-Day Symbology: Heat Map Dark Magenta-Yellow, Method: Constant, Radius: 20
Year to Date (YTD): Heat Map Blue-Cyan, Method: Constant, Radius: 20
ChatGPT said:
Perfect ‚Äî I see all the context now from your earlier uploads and notes! Quick Answers:
Case Sensitivity:
Since your data is a Hosted Feature Layer from ArcGIS Online, text matching is NOT case-sensitive. So Disposition CONTAINS 'report' will match Report, REPORT, report, etc. ‚úÖ
No special handling needed. Definition Query Code:
You want three different dynamic queries:

7-Day

28-Day

Year-to-Date (YTD)

I'll write clean ArcPy code for you that:

Reads dates from your Excel file (7_Day_Start, 7_Day_End, etc.) Applies correct Definition Queries to the layers. Filters Disposition and Call Type based on your provided keywords. Here‚Äôs the full Python script to do what you asked:

üî• Highlights:
7-Day Cycle: Filters between 7_Day_Start and 7_Day_End, plus Disposition and Call Type keywords. 28-Day Cycle: Filters between 28_Day_Start and 28_Day_End, plus Disposition and Call Type keywords. Year to Date: From 12/31/2024 onward, plus Disposition and Call Type keywords. Case Sensitivity? ‚úÖ Not an issue. ‚ú® Symbology Reminder:
7-Day: Square 3. 28-Day: Heat Map (Dark Magenta-Yellow, Radius: 20). YTD: Heat Map (Blue-Cyan, Radius: 20). Would you also like me to give you a second little script that automatically sets the symbology too, based on those settings? üöÄ

Provide Feedback | View Changes | Contribute. You said:
I imported the Calls For Service hosted Feature Service Feature Class. How do I implement the code? ChatGPT said:
Awesome ‚Äî you're really close! Let‚Äôs walk through it step-by-step very clearly:

üõ†Ô∏è You imported the Calls For Service hosted Feature Layer
Now you want to apply the dynamic Definition Queries to filter by 7-Day, 28-Day, and Year-to-Date automatically. üìã Here‚Äôs how to implement the code I gave you:
Step 1: Save the Python script
Open Notepad or VS Code or PyCharm. Copy the full Python script I provided earlier. Save it as something like:

apply_definition_queries.py
Step 2: Adjust the script slightly to match your actual Layer Names
üîµ Important:
In the script I assumed the layers were named:

7_Day_Incidents

28_Day_Incidents

Year_To_Date_Incidents

üëâ You need to change these names to whatever your real layer names are after you added the hosted feature service into ArcGIS Pro. Example:
If your layers are called:

Calls For Service 7-Day

Calls For Service 28-Day

Calls For Service YTD

You would modify the code in the apply_query function like this:

apply_query("Calls For Service 7-Day", query_7_day)
apply_query("Calls For Service 28-Day", query_28_day)
apply_query("Calls For Service YTD", query_ytd)
Step 3: Update the Excel path
In the script, change this line:

excel_path = r"C:\\path\\to\\7Day_28Day_Cycle_20250414.xlsx"
to the real path where your Excel file is located. (You can right-click the Excel file in Windows, click Properties, and copy the path.) Example:

excel_path = r"C:\\Users\\YourName\\Documents\\7Day_28Day_Cycle_20250414.xlsx"
Step 4: Run the Script inside ArcGIS Pro
Open ArcGIS Pro. Make sure your Calls For Service layers are loaded in the map. Open the Python window inside ArcGIS Pro:

Go to the View tab ‚ûî click Python. In the Python window, you can either:

Paste the script directly and hit Enter,

or Run the .py file by typing:

exec(open(r"C:\\path\\to\\apply_definition_queries.py").read())
‚úÖ If everything is correct, it will update the Definition Queries on the layers immediately. Step 5: Verify
Right-click each layer ‚Üí Properties ‚Üí Definition Query

You should see the queries auto-populated based on the latest 7-Day, 28-Day, or YTD dates! üì£ Quick Visual of How it Works:
flowchart TD
    A[Import Hosted Feature Layer] --> B[Save & Adjust Python Script]
    B --> C[Run Python Script in ArcGIS Pro]
    C --> D[Definition Queries Automatically Apply]
    D --> E[Your Map is Dynamically Filtered!] ‚ùì Notes:
Make sure your Call Date, Disposition, and Call Type fields match exactly (field names are case-sensitive in SQL expressions!). If you get errors, I can help you debug super quickly. Would you like me to also show you a slick way to turn this into a Toolbox Button in ArcGIS Pro ‚Äî so you just click once instead of opening Python every time? üéØ

(It's REALLY nice once you automate it.) Provide Feedback | View Changes | Contribute. You said:
The layer's names:
Burglary - Auto 7-Day
Burglary - Auto 28-Day
Burglary - Auto YTD

Burglary - Comm & Res 7-Day
Burglary - Comm & Res 28-Day
Burglary - Comm & Res YTD

Robbery 7-Day
Robbery 28-Day
Robbery YTD

Sexual Offenses 7-Day
Sexual Offenses 28-Day
Sexual Offenses YTD

MV Theft 7-Day
MV Theft 28-Day
MV Theft YTD
ChatGPT said:
‚úÖ I updated your script to match all your correct layer names (Burglary - Auto, Robbery, Sexual Offenses, MV Theft, etc.) for 7-Day, 28-Day, and YTD. Now the script will apply the correct query across all your layers automatically! Would you also like me to show you how to batch refresh the symbology right after the queries update? (It'll make it fully automatic.) üé®

Provide Feedback | View Changes | Contribute. You said:
show how to batch refresh
ChatGPT said:
‚úÖ I added a refresh_layer() function that forces ArcGIS Pro to refresh the symbology after applying each Definition Query! Now after you run the script:

The layer query updates

The symbology gets refreshed

Your map will always look clean and live üöÄ

Would you like me next to show you how to batch export the updated map to a PDF for each crime category automatically too? üó∫Ô∏èüìÑ

Provide Feedback | View Changes | Contribute. You said:
yes
ChatGPT said:
Perfect ‚Äî your code already has a really strong foundation! Now to batch export for each major crime category (like Robbery, MV Theft, etc. ), I‚Äôll update the code to turn off all other layers, turn on just one layer at a time, and export a PDF for each. Here‚Äôs the clean enhancement I‚Äôll make:

‚úÖ I updated your code so it batch exports a separate PDF for each crime type:

Burglary - Auto

Burglary - Comm & Res

Robbery

Sexual Offenses

MV Theft

Each PDF filename includes the report due date automatically! Would you also like a "bonus" feature that zips all the exported PDFs into one ZIP file at the end? üì¶ (It's super clean for emailing or archiving.) Provide Feedback | View Changes | Contribute. You said:
can we continue this conversation later. You can then provide steps on how to implement the code and what is needed to refresh the maps
ChatGPT said:
Of course! You can pause here ‚Äî whenever you‚Äôre ready to continue, we‚Äôll pick it up smoothly from this exact spot. ‚úÖ Next time you come back, I‚Äôll walk you through:

Step-by-step how to implement and run this code inside ArcGIS Pro

What is needed to refresh maps and ensure exports work perfectly

Bonus tips like automating the workflow even further if you want! Take your time ‚Äî just send a quick message when you‚Äôre ready to continue. I‚Äôll be here! üëã

Provide Feedback | View Changes | Contribute. You said:
Hey I‚Äôm back. Picking up on where we left off. Would setting up a template be a good solution to update the map and layouts weekly with updated data? ChatGPT said:
Hey, welcome back! Perfect timing ‚Äî let's pick it right up from where we paused. Short answer:

Yes, setting up a template is an excellent solution ‚Äî especially for your weekly updates! Here‚Äôs why a template is a great move for you:
Benefit	Why it Matters
Consistency	Same symbology, layers, layouts every time ‚Äî no manual resetting. Dynamic Data	Hosted feature layers pull live updated data automatically. Less Maintenance	Only the Excel file and layer visibility/queries need updates ‚Äî no rebuilding maps. Faster Exports	Just open, run script, export new PDFs ‚Äî 5 minutes instead of hours. Error Reduction	No accidentally forgetting to update dates or symbology manually. Scalable	You can easily add more crime types or maps later without redoing the setup. Ideal Setup (Based on your workflow):
ArcGIS Pro Project Template (.aprx):

All layers already added and styled. All layouts prebuilt (with dynamic text if you want!). Definition Queries controlled by the Python script (the one you have now). Link to your hosted feature layer and Excel sheet (OneDrive/local). Weekly Update Process:

Open the Template Project (or a copy of it). Update the Excel file with new dates. Run your Python script (refresh queries + export PDFs). Done. How you would build the template:
Set up your project exactly how you want (layers, layouts, bookmarks, settings). Save as Project Template (.aptx):

In ArcGIS Pro ‚Üí Share tab ‚Üí Project Template ‚Üí Save As. Save it to your local or organizational portal. Each week, you create a new project from the template:

It stays clean, no overwriting older work. You can even automate naming based on date (optional). Bonus:
Since your hosted feature service (Calls for Service) is live,
you won't even need to re-add or update the data source ‚Äî ArcGIS Pro will just pull the latest automatically! (Definition Queries keep everything filtered to just the right week/month/year.) Visual Summary:
flowchart TD
    A[Create Clean Project] --> B[Save as Template (.aptx)]
    B --> C[Each Week: Open New Project]
    C --> D[Update Excel File]
    D --> E[Run Python Script]
    E --> F[PDF Maps Exported, Ready!] Next Logical Step:
Would you like me to show you how to add dynamic text into your layouts (like ‚ÄúReporting Week: April 20‚ÄìApril 26‚Äù)? It will make your exported PDFs even more polished ‚Äî and fully automatic. Would you like me to lay out a clear action checklist for you too? (Like "Step 1, Step 2, Step 3" to get it all set up perfectly?) Provide Feedback | View Changes | Contribute. You said:
Before diving in the deep end can I ask more questions to better understand 
ChatGPT said:
Absolutely ‚Äî please ask as many questions as you want! That‚Äôs exactly the smart thing to do before diving deeper. I‚Äôm here to walk you through it clearly, no pressure, no rush. Go ahead ‚Äî what‚Äôs on your mind? (And feel free to ask even basic questions ‚Äî it‚Äôs important you‚Äôre 100% comfortable.) Provide Feedback | View Changes | Contribute. You said:
Can I save the template on my Departments OneDrive? Will the script you wrote automatically update the filter dates based on the excel file I provided (which is also saved on my OneDrive)
ChatGPT said:
These are great questions ‚Äî very smart to ask them now! Let‚Äôs break them down carefully:

1. Can you save the template on your Department‚Äôs OneDrive? ‚úÖ Yes, absolutely. ArcGIS Pro project templates (.aptx) are just files ‚Äî you can save them anywhere you have file access:

Local drive (C:\)

Network drives (H:\, S:\ etc.)