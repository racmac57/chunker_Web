Args:
        package_name: Name of the package to check
        
    Returns:
        True if installed, False otherwise
    """
    try:
        __import__(package_name)
        return True
    except ImportError:
        return False

def install_core_dependencies() -> Dict[str, bool]:
    """
    Install core dependencies. Returns:
        Dictionary of installation results
    """
    core_packages = [
        ("nltk>=3.9.1", "Natural Language Toolkit"),
        ("psutil>=5.9.0", "System and process utilities"),
        ("numpy>=1.22.5", "Numerical computing"),
        ("pandas>=2.2.3", "Data manipulation and analysis"),
        ("scikit-learn>=1.7.2", "Machine learning library"),
    ]
    
    results = {}
    for package, description in core_packages:
        results[package] = install_package(package, description)
    
    return results

def install_rag_dependencies() -> Dict[str, bool]:
    """
    Install RAG-specific dependencies. Returns:
        Dictionary of installation results
    """
    rag_packages = [
        ("ollama>=0.3.3", "Ollama for local embeddings"),
        ("faiss-cpu>=1.8.0", "FAISS for vector similarity search"),
        ("sentence-transformers>=3.1.1", "Sentence transformers for embeddings"),
        ("langchain>=0.3.1", "LangChain framework"),
        ("langchain-community>=0.3.1", "LangChain community packages"),
        ("langsmith>=0.1.129", "LangSmith for tracing and evaluation"),
    ]
    
    results = {}
    for package, description in rag_packages:
        results[package] = install_package(package, description)
    
    return results

def install_file_processing_dependencies() -> Dict[str, bool]:
    """
    Install file processing dependencies. Returns:
        Dictionary of installation results
    """
    file_packages = [
        ("openpyxl>=3.1.5", "Excel file processing"),
        ("pypdf2>=3.0.1", "PDF file processing"),
        ("python-docx>=1.2.0", "Word document processing"),
        ("pyyaml>=6.0.2", "YAML file processing"),
        ("lxml>=4.9.0", "XML file processing"),
    ]
    
    results = {}
    for package, description in file_packages:
        results[package] = install_package(package, description)
    
    return results

def install_evaluation_dependencies() -> Dict[str, bool]:
    """
    Install evaluation and metrics dependencies. Returns:
        Dictionary of installation results
    """
    eval_packages = [
        ("rouge-score>=0.1.2", "ROUGE metrics for text evaluation"),
        ("bert-score>=0.3.13", "BERTScore for semantic similarity"),
    ]
    
    results = {}
    for package, description in eval_packages:
        results[package] = install_package(package, description)
    
    return results

def install_monitoring_dependencies() -> Dict[str, bool]:
    """
    Install monitoring and scheduling dependencies. Returns:
        Dictionary of installation results
    """
    monitoring_packages = [
        ("watchdog>=3.0.0", "File system monitoring"),
        ("schedule>=1.2.0", "Task scheduling"),
    ]
    
    results = {}
    for package, description in monitoring_packages:
        results[package] = install_package(package, description)
    
    return results

def install_optional_dependencies() -> Dict[str, bool]:
    """
    Install optional dependencies. Returns:
        Dictionary of installation results
    """
    optional_packages = [
        ("pdfminer.six>=20221105", "Alternative PDF processor"),
        ("pymupdf>=1.23.0", "Another PDF processing option"),
        ("chromadb>=0.5.11", "ChromaDB vector database (may fail on Windows)"),
    ]
    
    results = {}
    for package, description in optional_packages:
        results[package] = install_package(package, description)
    
    return results

def install_development_dependencies() -> Dict[str, bool]:
    """
    Install development and testing dependencies. Returns:
        Dictionary of installation results
    """
    dev_packages = [
        ("pytest>=7.0.0", "Testing framework"),
        ("pytest-cov>=4.0.0", "Test coverage"),
        ("black>=23.0.0", "Code formatting"),
        ("flake8>=6.0.0", "Code linting"),
        ("mypy>=1.0.0", "Type checking"),
    ]
    
    results = {}
    for package, description in dev_packages:
        results[package] = install_package(package, description)
    
    return results

def check_ollama_availability() -> bool:
    """
    Check if Ollama is available and the model is installed. Returns:
        True if Ollama is available, False otherwise
    """
    try:
        import ollama
        # Try to list models
        models = ollama.list()
        print(f"‚úì Ollama is available with {len(models.get('models', []))} models")
        
        # Check for nomic-embed-text model
        model_names = [model['name'] for model in models.get('models', [])]
        if any('nomic-embed-text' in name for name in model_names):
            print("‚úì nomic-embed-text model is available")
            return True
        else:
            print("‚ö† nomic-embed-text model not found. Run: ollama pull nomic-embed-text")
            return False
            
    except ImportError:
        print("‚úó Ollama package not available")
        return False
    except Exception as e:
        print(f"‚úó Error checking Ollama: {e}")
        return False

def create_requirements_file() -> None:
    """
    Create requirements.txt file with all dependencies.
    """ requirements = [
        "# Core dependencies",
        "nltk>=3.9.1",
        "psutil>=5.9.0",
        "numpy>=1.22.5",
        "pandas>=2.2.3",
        "scikit-learn>=1.7.2",
        "",
        "# RAG and Vector Database",
        "ollama>=0.3.3",
        "faiss-cpu>=1.8.0",
        "sentence-transformers>=3.1.1",
        "langchain>=0.3.1",
        "langchain-community>=0.3.1",
        "langsmith>=0.1.129",
        "",
        "# File Processing",
        "openpyxl>=3.1.5",
        "pypdf2>=3.0.1",
        "python-docx>=1.2.0",
        "pyyaml>=6.0.2",
        "lxml>=4.9.0",
        "",
        "# Evaluation Metrics",
        "rouge-score>=0.1.2",
        "bert-score>=0.3.13",
        "",
        "# Monitoring and Scheduling",
        "watchdog>=3.0.0",
        "schedule>=1.2.0",
        "",
        "# Optional Dependencies",
        "pdfminer.six>=20221105",
        "pymupdf>=1.23.0",
        "# chromadb>=0.5.11  # May fail on Windows",
        "",
        "# Development and Testing",
        "pytest>=7.0.0",
        "pytest-cov>=4.0.0",
        "black>=23.0.0",
        "flake8>=6.0.0",
        "mypy>=1.0.0",
    ]
    
    try:
        with open("requirements_rag.txt", "w") as f:
            f.write("\n".join(requirements))
        print("‚úì Created requirements_rag.txt file")
    except Exception as e:
        print(f"‚úó Failed to create requirements file: {e}")

def main():
    """
    Main installation function.
    """ print("Chunker_v2 RAG Dependencies Installation")
    print("=" * 50)
    
    # Track installation results
    all_results = {}
    
    # Install dependencies in order
    print("\n1. Installing core dependencies...")
    all_results["core"] = install_core_dependencies()
    
    print("\n2. Installing RAG dependencies...")
    all_results["rag"] = install_rag_dependencies()
    
    print("\n3. Installing file processing dependencies...")
    all_results["file_processing"] = install_file_processing_dependencies()
    
    print("\n4. Installing evaluation dependencies...")
    all_results["evaluation"] = install_evaluation_dependencies()
    
    print("\n5. Installing monitoring dependencies...")
    all_results["monitoring"] = install_monitoring_dependencies()
    
    print("\n6. Installing optional dependencies...")
    all_results["optional"] = install_optional_dependencies()
    
    print("\n7. Installing development dependencies...")
    all_results["development"] = install_development_dependencies()
    
    # Check Ollama availability
    print("\n8. Checking Ollama availability...")
    ollama_available = check_ollama_availability()
    
    # Create requirements file
    print("\n9. Creating requirements file...")
    create_requirements_file()
    
    # Summary
    print("\n" + "=" * 50)
    print("Installation Summary:")
    print("=" * 50)
    
    total_packages = 0
    successful_packages = 0
    
    for category, results in all_results.items():
        category_total = len(results)
        category_successful = sum(1 for success in results.values() if success)
        
        total_packages += category_total
        successful_packages += category_successful
        
        print(f"{category}: {category_successful}/{category_total} packages installed")
    
    print(f"\nOverall: {successful_packages}/{total_packages} packages installed")
    
    if ollama_available:
        print("‚úì Ollama is ready for use")
    else:
        print("‚ö† Ollama setup required:")
        print("  1. Install Ollama: https://ollama.ai/")
        print("  2. Pull model: ollama pull nomic-embed-text")
    
    # Next steps
    print("\nNext Steps:")
    print("1. Run: python watcher_splitter.py (to build knowledge base)")
    print("2. Run: python rag_search.py (to search knowledge base)")
    print("3. Run: python automated_eval.py (for evaluation)")
    
    if successful_packages == total_packages:
        print("\nüéâ All dependencies installed successfully!") else:
        print(f"\n‚ö† {total_packages - successful_packages} packages failed to install")
        print("Check the error messages above for details")

if __name__ == "__main__":
    main()
```

Now let me update the todos and create a comprehensive README update:


Let me read the current README to understand its structure and then update it:


Now let me update the README with comprehensive information about all the new RAG features:


```markdown
# Chunker_v2 - Enterprise RAG-Powered File Processing System

**Version 2.0** - Enhanced with comprehensive RAG (Retrieval-Augmented Generation) capabilities, real-time monitoring, and advanced evaluation metrics. ## üöÄ What's New in v2.0

- **üîç Advanced RAG System**: Ollama + FAISS for local embeddings and semantic search
- **üìä Comprehensive Evaluation**: Precision@K, Recall@K, MRR, ROUGE, BLEU, Faithfulness scoring
- **üîó LangSmith Integration**: Tracing, evaluation, and feedback collection
- **‚ö° Real-time Monitoring**: Watchdog-based file system monitoring with debouncing
- **ü§ñ Hybrid Search**: Combines semantic similarity with keyword matching
- **üìà Automated Evaluation**: Scheduled testing with regression detection
- **üõ°Ô∏è Production Ready**: Graceful degradation, error handling, and monitoring

## Directory Structure

- **C:/_chunker** - Main project directory with scripts
- **02_data/** - Input files to be processed (watch folder)
- **03_archive/** - Archived original files and processed source files
- **04_output/** - Generated chunks and transcripts (organized by source file)
- **05_logs/** - Application logs and tracking
- **06_config/** - Configuration files
- **faiss_index/** - FAISS vector database storage
- **evaluations/** - RAG evaluation results
- **reports/** - Automated evaluation reports

## Quick Start

1. Place files to process in `02_data/` folder
2. Run the watcher: `python watcher_splitter.py`
3. Check `04_output/` for processed chunks and transcripts
4. Original files are moved to `03_archive/` after processing

## Features

- [x] Organized output by source file name
- [x] Admin files output as .md with headers
- [x] All other files output as .txt
- [x] Automatic file organization and archiving
- [x] Database tracking and logging
- [x] **Unicode filename support** - Handles files with emojis, special characters, and symbols
- [x] **Enhanced filename sanitization** - Automatically cleans problematic characters while preserving readability
- [x] **Timestamp-organized output** - Output folders include processing timestamp (YYYY_MM_DD_HH_MM_SS_) for chronological organization
- [x] **RAG Integration** - ChromaDB vector database for semantic search and knowledge base
- [x] **Multi-file type support** - Processes .txt, .md, .json, .csv, .xlsx, .pdf, .py, .docx, .sql, .yaml, .xml, .log
- [x] **Faithfulness scoring** - Evaluates answer grounding in source context
- [x] **RAG evaluation metrics** - Precision@K, Recall@K, MRR, ROUGE, BLEU scores
- [x] **LangSmith integration** - Tracing and evaluation capabilities (optional)

## Configuration

Edit `config.json` to customize:
- File filter modes (all, patterns, suffix)
- Supported file extensions
- Chunk sizes and processing options
- Notification settings
- RAG settings (ChromaDB, LangSmith)

## RAG Usage

### Setup
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Enable RAG in `config.json`: Set `"rag_enabled": true`
3. Start the watcher: `python watcher_splitter.py`

### Search Knowledge Base
```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

### RAG Query Example

Here's how to use the RAG search functionality:

```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

**Example Output:**
```
Found 3 results:
Result 1:
File: excel_guide.md
Type: .md
Department: admin
Chunk: 1
Content: VLOOKUP is used to find values in a table. Syntax: VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup]). Use FALSE for exact matches...
Similarity Score: 0.847

Result 2:
File: troubleshooting.xlsx
Type: .xlsx
Department: admin
Chunk: 2
Content: Common VLOOKUP errors include #N/A when lookup value not found, #REF when table array is invalid...
Similarity Score: 0.723
```

**Testing RAG Performance:**
```bash
# Run automated tests
python rag_test.py

# Expected output:
# Tests passed: 4
# Tests failed: 1
# Overall score: 0.623
# üéâ All tests passed! ```

### Evaluation
```python
from rag_evaluation import RAGEvaluator
from rag_integration import FaithfulnessScorer

# Evaluate retrieval quality
evaluator = RAGEvaluator()
metrics = evaluator.evaluate_retrieval(ground_truth, retrieved)

# Evaluate answer faithfulness
scorer = FaithfulnessScorer()
score = scorer.calculate_faithfulness(answer, context)
```

### Supported File Types
- **Text files**: .txt, .md, .json, .csv, .sql, .log
- **Office files**: .xlsx (Excel), .docx (Word)
- **Code files**: .py (Python with AST parsing)
- **Data files**: .yaml, .xml
- **Documents**: .pdf (text extraction)

### RAG Features
- **Semantic search** using ChromaDB vector database
- **Hybrid search** combining semantic and keyword matching
- **Faithfulness scoring** to evaluate answer grounding
- **Comprehensive evaluation** with multiple metrics
- **LangSmith integration** for tracing and monitoring (optional)

```

```markdown
# Chunker_v2 - Enterprise RAG-Powered File Processing System

**Version 2.0** - Enhanced with comprehensive RAG (Retrieval-Augmented Generation) capabilities, real-time monitoring, and advanced evaluation metrics. ## üöÄ What's New in v2.0

- **üîç Advanced RAG System**: Ollama + FAISS for local embeddings and semantic search
- **üìä Comprehensive Evaluation**: Precision@K, Recall@K, MRR, ROUGE, BLEU, Faithfulness scoring
- **üîó LangSmith Integration**: Tracing, evaluation, and feedback collection
- **‚ö° Real-time Monitoring**: Watchdog-based file system monitoring with debouncing
- **ü§ñ Hybrid Search**: Combines semantic similarity with keyword matching
- **üìà Automated Evaluation**: Scheduled testing with regression detection
- **üõ°Ô∏è Production Ready**: Graceful degradation, error handling, and monitoring

## Directory Structure

- **C:/_chunker** - Main project directory with scripts
- **02_data/** - Input files to be processed (watch folder)
- **03_archive/** - Archived original files and processed source files
- **04_output/** - Generated chunks and transcripts (organized by source file)
- **05_logs/** - Application logs and tracking
- **06_config/** - Configuration files
- **faiss_index/** - FAISS vector database storage
- **evaluations/** - RAG evaluation results
- **reports/** - Automated evaluation reports

## üöÄ Quick Start

### Basic Usage (Core Chunking)
1. Place files to process in `02_data/` folder
2. Run the watcher: `python watcher_splitter.py`
3. Check `04_output/` for processed chunks and transcripts
4. Original files are moved to `03_archive/` after processing

### Advanced Usage (RAG-Enabled)
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Install Ollama and pull model: `ollama pull nomic-embed-text`
3. Enable RAG in `config.json`: Set `"rag_enabled": true`
4. Run the watcher: `python watcher_splitter.py`
5. Search knowledge base: `python rag_search.py`

## Features

- [x] Organized output by source file name
- [x] Admin files output as .md with headers
- [x] All other files output as .txt
- [x] Automatic file organization and archiving
- [x] Database tracking and logging
- [x] **Unicode filename support** - Handles files with emojis, special characters, and symbols
- [x] **Enhanced filename sanitization** - Automatically cleans problematic characters while preserving readability
- [x] **Timestamp-organized output** - Output folders include processing timestamp (YYYY_MM_DD_HH_MM_SS_) for chronological organization
- [x] **RAG Integration** - ChromaDB vector database for semantic search and knowledge base
- [x] **Multi-file type support** - Processes .txt, .md, .json, .csv, .xlsx, .pdf, .py, .docx, .sql, .yaml, .xml, .log
- [x] **Faithfulness scoring** - Evaluates answer grounding in source context
- [x] **RAG evaluation metrics** - Precision@K, Recall@K, MRR, ROUGE, BLEU scores
- [x] **LangSmith integration** - Tracing and evaluation capabilities (optional)

## Configuration

Edit `config.json` to customize:
- File filter modes (all, patterns, suffix)
- Supported file extensions
- Chunk sizes and processing options
- Notification settings
- RAG settings (ChromaDB, LangSmith)

## RAG Usage

### Setup
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Enable RAG in `config.json`: Set `"rag_enabled": true`
3. Start the watcher: `python watcher_splitter.py`

### Search Knowledge Base
```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

### RAG Query Example

Here's how to use the RAG search functionality:

```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

**Example Output:**
```
Found 3 results:
Result 1:
File: excel_guide.md
Type: .md
Department: admin
Chunk: 1
Content: VLOOKUP is used to find values in a table. Syntax: VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup]). Use FALSE for exact matches...
Similarity Score: 0.847

Result 2:
File: troubleshooting.xlsx
Type: .xlsx
Department: admin
Chunk: 2
Content: Common VLOOKUP errors include #N/A when lookup value not found, #REF when table array is invalid...
Similarity Score: 0.723
```

**Testing RAG Performance:**
```bash
# Run automated tests
python rag_test.py

# Expected output:
# Tests passed: 4
# Tests failed: 1
# Overall score: 0.623
# üéâ All tests passed! ```

### Evaluation
```python
from rag_evaluation import RAGEvaluator
from rag_integration import FaithfulnessScorer

# Evaluate retrieval quality
evaluator = RAGEvaluator()
metrics = evaluator.evaluate_retrieval(ground_truth, retrieved)

# Evaluate answer faithfulness
scorer = FaithfulnessScorer()
score = scorer.calculate_faithfulness(answer, context)
```

### Supported File Types
- **Text files**: .txt, .md, .json, .csv, .sql, .log
- **Office files**: .xlsx (Excel), .docx (Word)
- **Code files**: .py (Python with AST parsing)
- **Data files**: .yaml, .xml
- **Documents**: .pdf (text extraction)

### RAG Features
- **Semantic search** using ChromaDB vector database
- **Hybrid search** combining semantic and keyword matching
- **Faithfulness scoring** to evaluate answer grounding
- **Comprehensive evaluation** with multiple metrics
- **LangSmith integration** for tracing and monitoring (optional)

```

```markdown
# Chunker_v2 - Enterprise RAG-Powered File Processing System

**Version 2.0** - Enhanced with comprehensive RAG (Retrieval-Augmented Generation) capabilities, real-time monitoring, and advanced evaluation metrics. ## üöÄ What's New in v2.0

- **üîç Advanced RAG System**: Ollama + FAISS for local embeddings and semantic search
- **üìä Comprehensive Evaluation**: Precision@K, Recall@K, MRR, ROUGE, BLEU, Faithfulness scoring
- **üîó LangSmith Integration**: Tracing, evaluation, and feedback collection
- **‚ö° Real-time Monitoring**: Watchdog-based file system monitoring with debouncing
- **ü§ñ Hybrid Search**: Combines semantic similarity with keyword matching
- **üìà Automated Evaluation**: Scheduled testing with regression detection
- **üõ°Ô∏è Production Ready**: Graceful degradation, error handling, and monitoring

## Directory Structure

- **C:/_chunker** - Main project directory with scripts
- **02_data/** - Input files to be processed (watch folder)
- **03_archive/** - Archived original files and processed source files
- **04_output/** - Generated chunks and transcripts (organized by source file)
- **05_logs/** - Application logs and tracking
- **06_config/** - Configuration files
- **faiss_index/** - FAISS vector database storage
- **evaluations/** - RAG evaluation results
- **reports/** - Automated evaluation reports

## üöÄ Quick Start

### Basic Usage (Core Chunking)
1. Place files to process in `02_data/` folder
2. Run the watcher: `python watcher_splitter.py`
3. Check `04_output/` for processed chunks and transcripts
4. Original files are moved to `03_archive/` after processing

### Advanced Usage (RAG-Enabled)
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Install Ollama and pull model: `ollama pull nomic-embed-text`
3. Enable RAG in `config.json`: Set `"rag_enabled": true`
4. Run the watcher: `python watcher_splitter.py`
5. Search knowledge base: `python rag_search.py`

## ‚ú® Features

### Core Chunking
- [x] **Organized output** by source file name with timestamp prefixes
- [x] **Multi-file type support** - .txt, .md, .json, .csv, .xlsx, .pdf, .py, .docx, .sql, .yaml, .xml, .log
- [x] **Unicode filename support** - Handles files with emojis, special characters, and symbols
- [x] **Enhanced filename sanitization** - Automatically cleans problematic characters
- [x] **Database tracking and logging** - Comprehensive activity monitoring
- [x] **Automatic file organization** - Moves processed files to archive

### RAG System (v2.0)
- [x] **Ollama Integration** - Local embeddings with nomic-embed-text model
- [x] **FAISS Vector Database** - High-performance similarity search
- [x] **Hybrid Search** - Combines semantic similarity with keyword matching
- [x] **ChromaDB Support** - Alternative vector database (optional)
- [x] **Real-time Monitoring** - Watchdog-based file system monitoring
- [x] **Debounced Processing** - Prevents race conditions and duplicate processing

### Evaluation & Quality Assurance
- [x] **Comprehensive Metrics** - Precision@K, Recall@K, MRR, NDCG@K
- [x] **Generation Quality** - ROUGE-1/2/L, BLEU, BERTScore
- [x] **Faithfulness Scoring** - Evaluates answer grounding in source context
- [x] **Context Utilization** - Measures how much context is used in answers
- [x] **Automated Evaluation** - Scheduled testing with regression detection
- [x] **LangSmith Integration** - Tracing, evaluation, and feedback collection

### Production Features
- [x] **Graceful Degradation** - Continues working even if RAG components fail
- [x] **Error Handling** - Robust error recovery and logging
- [x] **Performance Monitoring** - System metrics and performance tracking
- [x] **Security Redaction** - PII masking in metadata
- [x] **Modular Architecture** - Clean separation of concerns

## Configuration

Edit `config.json` to customize:
- File filter modes (all, patterns, suffix)
- Supported file extensions
- Chunk sizes and processing options
- Notification settings
- RAG settings (ChromaDB, LangSmith)

## RAG Usage

### Setup
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Enable RAG in `config.json`: Set `"rag_enabled": true`
3. Start the watcher: `python watcher_splitter.py`

### Search Knowledge Base
```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

### RAG Query Example

Here's how to use the RAG search functionality:

```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

**Example Output:**
```
Found 3 results:
Result 1:
File: excel_guide.md
Type: .md
Department: admin
Chunk: 1
Content: VLOOKUP is used to find values in a table. Syntax: VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup]). Use FALSE for exact matches...
Similarity Score: 0.847

Result 2:
File: troubleshooting.xlsx
Type: .xlsx
Department: admin
Chunk: 2
Content: Common VLOOKUP errors include #N/A when lookup value not found, #REF when table array is invalid...
Similarity Score: 0.723
```

**Testing RAG Performance:**
```bash
# Run automated tests
python rag_test.py

# Expected output:
# Tests passed: 4
# Tests failed: 1
# Overall score: 0.623
# üéâ All tests passed! ```

### Evaluation
```python
from rag_evaluation import RAGEvaluator
from rag_integration import FaithfulnessScorer

# Evaluate retrieval quality
evaluator = RAGEvaluator()
metrics = evaluator.evaluate_retrieval(ground_truth, retrieved)

# Evaluate answer faithfulness
scorer = FaithfulnessScorer()
score = scorer.calculate_faithfulness(answer, context)
```

### Supported File Types
- **Text files**: .txt, .md, .json, .csv, .sql, .log
- **Office files**: .xlsx (Excel), .docx (Word)
- **Code files**: .py (Python with AST parsing)
- **Data files**: .yaml, .xml
- **Documents**: .pdf (text extraction)

### RAG Features
- **Semantic search** using ChromaDB vector database
- **Hybrid search** combining semantic and keyword matching
- **Faithfulness scoring** to evaluate answer grounding
- **Comprehensive evaluation** with multiple metrics
- **LangSmith integration** for tracing and monitoring (optional)

```

```markdown
# Chunker_v2 - Enterprise RAG-Powered File Processing System

**Version 2.0** - Enhanced with comprehensive RAG (Retrieval-Augmented Generation) capabilities, real-time monitoring, and advanced evaluation metrics. ## üöÄ What's New in v2.0

- **üîç Advanced RAG System**: Ollama + FAISS for local embeddings and semantic search
- **üìä Comprehensive Evaluation**: Precision@K, Recall@K, MRR, ROUGE, BLEU, Faithfulness scoring
- **üîó LangSmith Integration**: Tracing, evaluation, and feedback collection
- **‚ö° Real-time Monitoring**: Watchdog-based file system monitoring with debouncing
- **ü§ñ Hybrid Search**: Combines semantic similarity with keyword matching
- **üìà Automated Evaluation**: Scheduled testing with regression detection
- **üõ°Ô∏è Production Ready**: Graceful degradation, error handling, and monitoring

## Directory Structure

- **C:/_chunker** - Main project directory with scripts
- **02_data/** - Input files to be processed (watch folder)
- **03_archive/** - Archived original files and processed source files
- **04_output/** - Generated chunks and transcripts (organized by source file)
- **05_logs/** - Application logs and tracking
- **06_config/** - Configuration files
- **faiss_index/** - FAISS vector database storage
- **evaluations/** - RAG evaluation results
- **reports/** - Automated evaluation reports

## üöÄ Quick Start

### Basic Usage (Core Chunking)
1. Place files to process in `02_data/` folder
2. Run the watcher: `python watcher_splitter.py`
3. Check `04_output/` for processed chunks and transcripts
4. Original files are moved to `03_archive/` after processing

### Advanced Usage (RAG-Enabled)
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Install Ollama and pull model: `ollama pull nomic-embed-text`
3. Enable RAG in `config.json`: Set `"rag_enabled": true`
4. Run the watcher: `python watcher_splitter.py`
5.