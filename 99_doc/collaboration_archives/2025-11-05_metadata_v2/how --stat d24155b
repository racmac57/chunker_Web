[1mdiff --git a/CHANGELOG.md b/CHANGELOG.md[m
[1mindex 3bb8b6f..afb37c3 100644[m
[1m--- a/CHANGELOG.md[m
[1m+++ b/CHANGELOG.md[m
[36m@@ -13,6 +13,60 @@[m [mand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0[m
 [m
 ---[m
 [m
[32m+[m[32m## [v2.2.1] - 2025-11-06 - Operational Enhancements & Caching[m
[32m+[m
[32m+[m[32m### Added[m
[32m+[m[32m- **Query Cache**: In-memory LRU + TTL cache for RAG searches with optional memory guard, stats API (`GET /api/cache/stats`), and config defaults under `query_cache`.[m
[32m+[m[32m- **Incremental Updates**: Thread-safe `VersionTracker` shared by watcher/backfill to hash inputs, skip untouched sources, and clean up stale chunk IDs.[m
[32m+[m[32m- **Metadata Enrichment Workflow**: Shared heuristics module powering manifest, sidecar, and ChromaDB tagging with tag-aware chunk filenames.[m
[32m+[m[32m- **Backup Manager**: Scheduled tar.gz lifecycle (`backup_manager.py`) with watcher integration and CLI support.[m
[32m+[m[32m- **Monitoring System**: Disk/throughput/Chroma checks feeding the notification pipeline with configurable thresholds and cooldowns.[m
[32m+[m
[32m+[m[32m### Changed[m
[32m+[m[32m- **watcher_splitter.py**: Unified feature initialization, version tracking, enriched manifest/sidecar writes, duplicate skipping, and automated backup scheduling.[m
[32m+[m[32m- **backfill_knowledge_base.py**: Respects incremental tracker state, merges enrichment payloads, and records dedup/query cache metadata for Chroma ingestion.[m
[32m+[m[32m- **rag_integration.py** / **api_server.py**: Cache-aware search path with stats surfacing plus resilience improvements for repeated lookups.[m
[32m+[m[32m- **config.json**: Expanded with `query_cache`, `incremental_updates`, `monitoring`, and `backup` sections (all disabled by default for backwards compatibility).[m
[32m+[m
[32m+[m[32m### Documentation[m
[32m+[m[32m- `README.md`: Refreshed Feature Toggles section with query cache metrics, incremental update behavior, and backup/monitoring guidance.[m
[32m+[m[32m- `docs/METADATA_SCHEMA.md`: Documented enrichment schema, tag rules, and ChromaDB metadata fields.[m
[32m+[m[32m- `CHANGELOG.md`: Captures integrated feature set and testing steps.[m
[32m+[m
[32m+[m[32m### Testing[m
[32m+[m[32m- `pytest tests/test_query_cache.py`[m
[32m+[m[32m- `pytest tests/test_incremental_updates.py`[m
[32m+[m[32m- `pytest tests/test_backup_manager.py`[m
[32m+[m[32m- Targeted watcher/backfill dry runs with feature toggles (metadata enrichment, dedup, incremental updates, query cache, backup, monitoring) enabled.[m
[32m+[m
[32m+[m[32m---[m
[32m+[m
[32m+[m[32m## [v2.2.0] - 2025-11-06 - Feature Toggle Integration & QA[m
[32m+[m
[32m+[m[32m### Added[m
[32m+[m[32m- **Metadata Enrichment Pipeline** gated by `metadata_enrichment.enabled`, producing tags, summaries, and manifest enrichment.[m
[32m+[m[32m- **Incremental Updates** with `VersionTracker` support across watcher and backfill for hash-based skip + artifact cleanup.[m
[32m+[m[32m- **Monitoring System Integration** wiring runtime health checks into the watcher loop with optional alerts.[m
[32m+[m[32m- **Backup Scheduler Hooks** to start/stop `BackupManager` from the watcher when enabled.[m
[32m+[m[32m- **End-to-End Tests** in `tests/test_enhancements.py` covering metadata sidecars, incremental skips, and dedup stubs.[m
[32m+[m
[32m+[m[32m### Changed[m
[32m+[m[32m- **watcher_splitter.py**: Refactored feature initialization, optional metadata flow, incremental cleanup, and dedup stats.[m
[32m+[m[32m- **backfill_knowledge_base.py**: Added incremental filtering/recording and shared dedup + metadata handling improvements.[m
[32m+[m[32m- **config.json**: Introduced `metadata_enrichment` and `incremental_updates` sections (defaults disabled) and aligned toggle defaults.[m
[32m+[m[32m- **rag_integration.py**: Query cache now respects config defaults (already present, documented).[m
[32m+[m
[32m+[m[32m### Documentation[m
[32m+[m[32m- `README.md`: New â€œFeature Toggles & Setupâ€ section covering metadata tagging, monitoring, dedup, caching, incremental updates, and backups.[m
[32m+[m[32m- `docs/METADATA_SCHEMA.md`: Serves as canonical schema reference for enriched sidecars/manifests.[m
[32m+[m[32m- `CHANGELOG.md`: Updated with integration release notes.[m
[32m+[m
[32m+[m[32m### Testing[m
[32m+[m[32m- `pytest tests/test_enhancements.py` validates metadata sidecar generation, incremental skip behaviour, and dedup statistics.[m
[32m+[m[32m- Verification scripts (`verify_chunk_completeness.py`, dedup cleanup) executed to ensure regression safety.[m
[32m+[m
[32m+[m[32m---[m
[32m+[m
 ## [v2.1.6] - 2025-11-05 - RAG Backfill Optimization and Multiprocessing[m
 [m
 ### Added[m
[1mdiff --git a/Chunker_MoveOptimized.ps1 b/Chunker_MoveOptimized.ps1[m
[1mindex a0087a9..bd509a7 100644[m
[1m--- a/Chunker_MoveOptimized.ps1[m
[1m+++ b/Chunker_MoveOptimized.ps1[m
[36m@@ -8,6 +8,7 @@[m [mparam([m
 )[m
 [m
 $ErrorActionPreference = 'Continue'[m
[32m+[m[32m$script:HadErrors = $false[m
 $DestFolder = "C:\_chunker\02_data"[m
 $KeyFile = "C:\_chunker\06_config\manifest_hmac.key"[m
 [m
[36m@@ -83,7 +84,8 @@[m [mfunction Process-File {[m
         size_bytes = $fileInfo.Length[m
         modified_time = $fileInfo.LastWriteTimeUtc.ToString("o")[m
         created_time = $fileInfo.CreationTimeUtc.ToString("o")[m
[31m-        operation = "MOVE"  # NEW: Track operation type[m
[32m+[m[32m        operation = "MOVE"[m
[32m+[m[32m        source_cleanup = "pending"[m
     }[m
 [m
     # Try to MOVE file (primary operation)[m
[36m@@ -92,27 +94,86 @@[m [mfunction Process-File {[m
         Move-Item -Path $SourcePath -Destination $DestPath -Force -ErrorAction Stop[m
         $moveSuccess = $true[m
         Write-Host "[MOVE] Successfully moved: $($fileInfo.Name)" -ForegroundColor Green[m
[32m+[m
[32m+[m[32m        # Guard against OneDrive or sync clients restoring the original file immediately after move[m
[32m+[m[32m        Start-Sleep -Milliseconds 300[m
[32m+[m[32m        if (Test-Path $SourcePath) {[m
[32m+[m[32m            try {[m
[32m+[m[32m                Remove-Item -Path $SourcePath -Force -ErrorAction Stop[m
[32m+[m[32m                Write-Host "[CLEANUP] Removed residual source copy: $($fileInfo.Name)" -ForegroundColor DarkYellow[m
[32m+[m[32m                $manifest.source_cleanup = "removed_residual_copy"[m
[32m+[m[32m            } catch {[m
[32m+[m[32m                Write-Warning "Residual source copy could not be removed for $($fileInfo.Name): $_"[m
[32m+[m[32m                $manifest.source_cleanup = "cleanup_failed"[m
[32m+[m[32m                $manifest.source_cleanup_error = $_.ToString()[m
[32m+[m[32m                $script:HadErrors = $true[m
[32m+[m[32m            }[m
[32m+[m[32m        } else {[m
[32m+[m[32m            $manifest.source_cleanup = "not_required"[m
[32m+[m[32m        }[m
     } catch {[m
[32m+[m[32m        $moveError = $_[m
         # Fallback to COPY if MOVE fails[m
[31m-        Write-Warning "MOVE failed for $($fileInfo.Name): $_"[m
[32m+[m[32m        Write-Warning "MOVE failed for $($fileInfo.Name): $moveError"[m
         Write-Warning "Falling back to COPY operation"[m
[31m-        $manifest.operation = "COPY_FALLBACK"  # Track fallback[m
[32m+[m[32m        $manifest.operation = "COPY_FALLBACK"[m
[32m+[m[32m        $manifest.move_error = $moveError.ToString()[m
         [m
         try {[m
             Copy-Item -Path $SourcePath -Destination $DestPath -Force -ErrorAction Stop[m
             Write-Host "[COPY] Used fallback for: $($fileInfo.Name)" -ForegroundColor Yellow[m
             [m
             # Update manifest to reflect we're using original file[m
[31m-            $manifest.fallback_reason = $_.ToString()[m
[32m+[m[32m            $manifest.fallback_reason = $moveError.ToString()[m
[32m+[m
[32m+[m[32m            Start-Sleep -Milliseconds 300[m
[32m+[m[32m            if (Test-Path $SourcePath) {[m
[32m+[m[32m                try {[m
[32m+[m[32m                    Remove-Item -Path $SourcePath -Force -ErrorAction Stop[m
[32m+[m[32m                    Write-Host "[CLEANUP] Removed source after copy fallback: $($fileInfo.Name)" -ForegroundColor DarkYellow[m
[32m+[m[32m                    $manifest.source_cleanup = "removed_after_copy"[m
[32m+[m[32m                } catch {[m
[32m+[m[32m                    Write-Warning "Failed to remove source after copy fallback for $($fileInfo.Name): $_"[m
[32m+[m[32m                    $manifest.source_cleanup = "cleanup_failed_after_copy"[m
[32m+[m[32m                    $manifest.source_cleanup_error = $_.ToString()[m
[32m+[m[32m                    $script:HadErrors = $true[m
[32m+[m[32m                }[m
[32m+[m[32m            } else {[m
[32m+[m[32m                $manifest.source_cleanup = "not_found_after_copy"[m
[32m+[m[32m            }[m
         } catch {[m
             Write-Warning "Both MOVE and COPY failed for $SourcePath : $_"[m
[32m+[m[32m            $manifest.operation = "FAILED"[m
[32m+[m[32m            $manifest.copy_error = $_.ToString()[m
[32m+[m[32m            $script:HadErrors = $true[m
             return[m
         }[m
     }[m
 [m
[32m+[m[32m    if (Test-Path $DestPath) {[m
[32m+[m[32m        $manifest.destination_status = "present"[m
[32m+[m[32m    } else {[m
[32m+[m[32m        Write-Warning "Destination missing after operation for $($fileInfo.Name)"[m
[32m+[m[32m        $manifest.destination_status = "missing"[m
[32m+[m[32m        $script:HadErrors = $true[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    if (Test-Path $SourcePath) {[m
[32m+[m[32m        Write-Warning "Source still present after operation for $($fileInfo.Name)"[m
[32m+[m[32m        if ($manifest.source_cleanup -eq "pending") {[m
[32m+[m[32m            $manifest.source_cleanup = "source_still_present"[m
[32m+[m[32m        }[m
[32m+[m[32m        $script:HadErrors = $true[m
[32m+[m[32m    } elseif ($manifest.source_cleanup -eq "pending") {[m
[32m+[m[32m        $manifest.source_cleanup = "cleared"[m
[32m+[m[32m    }[m
[32m+[m
     # Write manifest (regardless of MOVE/COPY)[m
     try {[m
         $manifestPath = "$DestPath.origin.json"[m
[32m+[m[32m        if (-not $manifest.ContainsKey('source_cleanup')) {[m
[32m+[m[32m            $manifest.source_cleanup = "not_applicable"[m
[32m+[m[32m        }[m
         $manifestJson = $manifest | ConvertTo-Json -Depth 10[m
         [m
         [System.IO.File]::WriteAllText($manifestPath, $manifestJson, [System.Text.Encoding]::UTF8)[m
[36m@@ -185,5 +246,9 @@[m [mWrite-Host "===============================================" -ForegroundColor Wh[m
 Write-Host "Processing Complete" -ForegroundColor Green[m
 Write-Host "===============================================" -ForegroundColor White[m
 [m
[31m-exit 0[m
[32m+[m[32mif ($script:HadErrors) {[m
[32m+[m[32m    exit 1[m
[32m+[m[32m} else {[m
[32m+[m[32m    exit 0[m
[32m+[m[32m}[m
 [m
[1mdiff --git a/README.md b/README.md[m
[1mindex cbf3d89..c4cbd5a 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -139,6 +139,62 @@[m [mFor high-volume processing and advanced task management:[m
    export FLOWER_PASSWORD="your_secure_password"[m
    ```[m
 [m
[32m+[m[32m## âš™ï¸ Feature Toggles & Setup[m
[32m+[m
[32m+[m[32mAll new subsystems ship **disabled by default** so existing deployments behave exactly as before. Enable individual features by updating `config.json` in the project root.[m
[32m+[m
[32m+[m[32m### Metadata Enrichment (`metadata_enrichment`)[m
[32m+[m[32m- Adds semantic tags, key terms, summaries, and source metadata to chunk sidecars and manifests.[m
[32m+[m[32m- Output schema documented in `docs/METADATA_SCHEMA.md`.[m
[32m+[m[32m- Enable with:[m
[32m+[m[32m  ```json[m
[32m+[m[32m  "metadata_enrichment": { "enabled": true }[m
[32m+[m[32m  ```[m
[32m+[m
[32m+[m[32m### Monitoring & Health Checks (`monitoring`)[m
[32m+[m[32m- Background thread performs disk, throughput, and ChromaDB checks and escalates via the notification system.[m
[32m+[m[32m- Configure thresholds in `config.json` under the `monitoring` section; default recipients come from `notification_system.py`.[m
[32m+[m[32m- Start by setting `"monitoring": { "enabled": true }`.[m
[32m+[m
[32m+[m[32m### Deduplication (`deduplication`)[m
[32m+[m[32m- Prevents duplicate chunks from entering ChromaDB in both watcher and backfill flows.[m
[32m+[m[32m- Optionally run cleanup via `python deduplication.py --auto-remove`.[m
[32m+[m[32m- Already present in `config.json`; flip `"enabled": true` to activate.[m
[32m+[m
[32m+[m[32m### Query Cache (`query_cache`)[m
[32m+[m[32m- Enables an in-memory LRU + TTL cache in `rag_integration.py` so repeat queries avoid hitting ChromaDB.[m
[32m+[m[32m- Configure `max_size`, `ttl_hours`, and optional `memory_limit_mb` under the `query_cache` section.[m
[32m+[m[32m- API users can inspect runtime metrics via `GET /api/cache/stats` once the cache is enabled.[m
[32m+[m[32m- Minimal example:[m
[32m+[m[32m  ```json[m
[32m+[m[32m  "query_cache": {[m
[32m+[m[32m    "enabled": true,[m
[32m+[m[32m    "max_size": 256,[m
[32m+[m[32m    "ttl_hours": 1,[m
[32m+[m[32m    "memory_limit_mb": 64[m
[32m+[m[32m  }[m
[32m+[m[32m  ```[m
[32m+[m
[32m+[m[32m### Incremental Updates (`incremental_updates`)[m
[32m+[m[32m- Uses a shared `VersionTracker` to hash inputs, skip untouched files, remove old chunk IDs, and persist deterministic chunk identifiers.[m
[32m+[m[32m- Tracker state defaults to `06_config/file_versions.json` (override with `version_file`).[m
[32m+[m[32m- Typical configuration:[m
[32m+[m[32m  ```json[m
[32m+[m[32m  "incremental_updates": {[m
[32m+[m[32m    "enabled": true,[m
[32m+[m[32m    "version_file": "06_config/file_versions.json",[m
[32m+[m[32m    "hash_algorithm": "sha256"[m
[32m+[m[32m  }[m
[32m+[m[32m  ```[m
[32m+[m[32m- After enabling, unchanged files are skipped by the watcher/backfill, while reprocessed sources clean up stale artifacts before writing new chunks.[m
[32m+[m
[32m+[m[32m### Backup Manager (`backup`)[m
[32m+[m[32m- Creates compressed archives of ChromaDB and critical directories on a schedule.[m
[32m+[m[32m- Configure destination, retention, and schedule in the `backup` section.[m
[32m+[m[32m- Manual run: `python backup_manager.py --config config.json create --label on-demand`.[m
[32m+[m
[32m+[m[32mAfter toggling features, restart the watcher (`python watcher_splitter.py`) so runtime components reinitialize with the new configuration.[m
[32m+[m
 ## âœ¨ Features[m
 [m
 ### Core Chunking[m
[1mdiff --git a/api_server.py b/api_server.py[m
[1mindex d5395b4..0f88c75 100644[m
[1m--- a/api_server.py[m
[1m+++ b/api_server.py[m
[36m@@ -84,6 +84,19 @@[m [mclass StatsResponse(BaseModel):[m
     collection_name: str[m
     last_updated: str[m
 [m
[32m+[m[32mclass CacheStatsResponse(BaseModel):[m
[32m+[m[32m    """Cache stats response model"""[m
[32m+[m[32m    max_size: int[m
[32m+[m[32m    ttl_seconds: float[m
[32m+[m[32m    memory_limit_bytes: Optional[int][m
[32m+[m[32m    current_size: int[m
[32m+[m[32m    memory_usage_bytes: int[m
[32m+[m[32m    hits: int[m
[32m+[m[32m    misses: int[m
[32m+[m[32m    hit_rate: float[m
[32m+[m[32m    evictions: int[m
[32m+[m[32m    invalidations: int[m
[32m+[m
 class ContextRequest(BaseModel):[m
     """Context request for LLM prompts"""[m
     query: str = Field(..., description="Query for context retrieval")[m
[36m@@ -113,6 +126,7 @@[m [masync def root():[m
             "chunk": "GET /api/chunk/{chunk_id}",[m
             "stats": "GET /api/stats",[m
             "context": "POST /api/context",[m
[32m+[m[32m            "cache_stats": "GET /api/cache/stats",[m
             "health": "GET /api/health"[m
         },[m
         "docs": "/docs",[m
[36m@@ -212,6 +226,20 @@[m [masync def get_stats():[m
         logger.error(f"Stats retrieval failed: {e}", exc_info=True)[m
         raise HTTPException(status_code=500, detail=f"Stats error: {str(e)}")[m
 [m
[32m+[m[32m@app.get("/api/cache/stats", response_model=CacheStatsResponse)[m
[32m+[m[32masync def get_cache_stats():[m
[32m+[m[32m    """[m
[32m+[m[32m    Get query cache statistics (if enabled).[m
[32m+[m[32m    """[m
[32m+[m[32m    if not rag:[m
[32m+[m[32m        raise HTTPException(status_code=503, detail="RAG system not initialized")[m
[32m+[m
[32m+[m[32m    stats = rag.get_query_cache_stats()[m
[32m+[m[32m    if stats is None:[m
[32m+[m[32m        raise HTTPException(status_code=404, detail="Query cache not enabled")[m
[32m+[m
[32m+[m[32m    return CacheStatsResponse(**stats)[m
[32m+[m
 @app.post("/api/context", response_model=ContextResponse)[m
 async def get_context(request: ContextRequest):[m
     """[m
[1mdiff --git a/backfill_knowledge_base.py b/backfill_knowledge_base.py[m
[1mindex 4d638a2..1175b81 100644[m
[1m--- a/backfill_knowledge_base.py[m
[1m+++ b/backfill_knowledge_base.py[m
[36m@@ -15,6 +15,7 @@[m [mFeatures:[m
 - Count discrepancy alerts[m
 """[m
 [m
[32m+[m[32mimport hashlib[m
 import os[m
 import sys[m
 import json[m
[36m@@ -23,12 +24,17 @@[m [mimport time[m
 import uuid[m
 from pathlib import Path[m
 from datetime import datetime[m
[31m-from typing import List, Dict, Any, Optional, Tuple, Union[m
[32m+[m[32mfrom typing import List, Dict, Any, Optional, Tuple, Union, Iterable[m
 import re[m
 import multiprocessing[m
 from multiprocessing import Pool, cpu_count[m
 from functools import partial[m
 [m
[32m+[m[32mtry:[m
[32m+[m[32m    from incremental_updates import VersionTracker[m
[32m+[m[32mexcept ImportError:[m
[32m+[m[32m    VersionTracker = None  # type: ignore[m
[32m+[m
 # Setup logging first (before other imports that might use logger)[m
 import logging[m
 logging.basicConfig([m
[36m@@ -57,6 +63,14 @@[m [mexcept ImportError:[m
     TQDM_AVAILABLE = False[m
     logger.warning("tqdm not available - progress bars disabled")[m
 [m
[32m+[m[32mtry:[m
[32m+[m[32m    from deduplication import DeduplicationManager[m
[32m+[m[32mexcept ImportError:[m
[32m+[m[32m    DeduplicationManager = None  # type: ignore[m
[32m+[m
[32m+[m[32mfrom metadata_enrichment import SIDECAR_SUFFIX, MANIFEST_ENRICHMENT_KEY[m
[32m+[m[32mfrom incremental_updates import VersionTracker, build_chunk_id, normalize_timestamp[m
[32m+[m
 # NLTK initialization (outside loop for performance)[m
 try:[m
     import nltk[m
[36m@@ -87,6 +101,12 @@[m [mdef load_config() -> Dict[str, Any]:[m
         sys.exit(1)[m
 [m
 [m
[32m+[m[32mdef compute_content_hash(text: str) -> str:[m
[32m+[m[32m    normalized = (text or "").strip().lower()[m
[32m+[m[32m    normalized = " ".join(normalized.split())[m
[32m+[m[32m    return hashlib.sha256(normalized.encode("utf-8")).hexdigest()[m
[32m+[m
[32m+[m
 def extract_keywords(text: str, max_keywords: int = 5) -> List[str]:[m
     """[m
     Extract keywords from text using simple frequency analysis[m
[36m@@ -115,6 +135,38 @@[m [mdef extract_keywords(text: str, max_keywords: int = 5) -> List[str]:[m
     return [word for word, _ in counter.most_common(max_keywords)][m
 [m
 [m
[32m+[m[32mdef dedupe_list(values: Optional[Iterable[Any]]) -> List[str]:[m
[32m+[m[32m    """[m
[32m+[m[32m    Deduplicate an iterable while preserving order and returning strings.[m
[32m+[m[32m    """[m
[32m+[m[32m    if not values:[m
[32m+[m[32m        return [][m
[32m+[m
[32m+[m[32m    seen = set()[m
[32m+[m[32m    ordered: List[str] = [][m
[32m+[m[32m    for value in values:[m
[32m+[m[32m        if value is None:[m
[32m+[m[32m            continue[m
[32m+[m[32