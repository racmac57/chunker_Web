# Verify file was written correctly
if os.path.getsize(chunk_file) > 0:
    chunk_files.append(chunk_file)
    valid_chunks += 1
    logger.info(f"Created chunk: {chunk_file.name} ({len(chunk)} chars)")
else:
    logger.warning(f"Zero-byte chunk prevented: {chunk_file.name}")
    session_stats["zero_byte_prevented"] += 1
    os.remove(chunk_file)  # Clean up
# ðŸ•’ 2025-06-27-22-45-30
# chunker/watcher_splitter.py  
# Author: R. A. Carucci
# Purpose: Enhanced chat log chunker with zero-byte prevention and robust file handling

import os
import sys
import time
import shutil
import logging
from datetime import datetime
from pathlib import Path
import nltk
from nltk.tokenize import sent_tokenize
import json

# Resolve config path (supports PyInstaller .exe)
if getattr(sys, 'frozen', False):
    base_path = sys._MEIPASS
else:
    base_path = os.path.dirname(__file__)

# Configure local nltk_data path
nltk_path = os.path.join(base_path, "nltk_data")
nltk.data.path.append(nltk_path)

try:
    nltk.download('punkt_tab', download_dir=nltk_path, quiet=True)
except:
    nltk.download('punkt', download_dir=nltk_path, quiet=True)

with open(os.path.join(base_path, "config.json")) as f:
    CONFIG = json.load(f)

os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    filename=CONFIG.get("log_file", "logs/watcher.log"),
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

# Session statistics
session_stats = {
    "files_processed": 0,
    "chunks_created": 0,
    "zero_byte_prevented": 0,
    "errors": 0
}

def chunk_text(text, limit):
    """Enhanced chunking with validation"""
    if not text or len(text.strip()) < 10:
        logger.warning("Text too short for chunking")
        return []
    
    try:
        sentences = sent_tokenize(text)
        if not sentences:
            logger.warning("No sentences found in text")
            return []
        
        chunks = []
        for i in range(0, len(sentences), limit):
            chunk = " ".join(sentences[i:i + limit])
            if len(chunk.strip()) > 0:  # Prevent empty chunks
                chunks.append(chunk)
        
        logger.info(f"Created {len(chunks)} chunks from {len(sentences)} sentences")
        return chunks
        
    except Exception as e:
        logger.error(f"Chunking failed: {e}")
        return []

def wait_for_file_stability(file_path, min_wait=2, max_wait=30):
    """Enhanced file stability check"""
    file_size = 0
    stable_count = 0
    wait_time = 0
    
    # Determine wait strategy based on file size
    try:
        initial_size = os.path.getsize(file_path)
        if initial_size < 1000:  # Small files
            target_stable = 2
            check_interval = 0.5
        else:  # Larger files
            target_stable = 3
            check_interval = 1
    except:
        target_stable = 2
        check_interval = 1
    
    while wait_time < max_wait:
        try:
            current_size = os.path.getsize(file_path)
            if current_size == file_size:
                stable_count += 1
                if stable_count >= target_stable:
                    logger.info(f"File stable after {wait_time}s: {file_path.name}")
                    return True
            else:
                file_size = current_size
                stable_count = 0
            
            time.sleep(check_interval)
            wait_time += check_interval
            
        except FileNotFoundError:
            logger.warning(f"File disappeared during stability check: {file_path}")
            return False
    
    logger.warning(f"File stability timeout after {max_wait}s: {file_path.name}")
    return True  # Proceed anyway

def validate_chunk_content(chunk, min_length=50):
    """Validate chunk before writing"""
    if not chunk or len(chunk.strip()) < min_length:
        return False
    
    # Check for reasonable content
    word_count = len(chunk.split())
    if word_count < 10:
        return False
    
    return True

def copy_to_cloud(chunk_files, cloud_dir):
    """Enhanced cloud copy with validation"""
    try:
        os.makedirs(cloud_dir, exist_ok=True)
        successful_copies = 0
        
        for file_path in chunk_files:
            if os.path.getsize(file_path) > 0:  # Only copy non-empty files
                shutil.copy(file_path, cloud_dir)
                successful_copies += 1
            else:
                logger.warning(f"Skipped zero-byte file: {file_path}")
        
        logger.info(f"Copied {successful_copies}/{len(chunk_files)} files to cloud")
        return successful_copies > 0
        
    except Exception as e:
        logger.exception(f"Cloud copy failed: {e}")
        return False

def move_to_processed(file_path, processed_folder):
    """Enhanced file moving with retry logic"""
    for attempt in range(3):
        try:
            os.makedirs(processed_folder, exist_ok=True)
            dest_path = Path(processed_folder) / file_path.name
            
            # Handle duplicate names
            counter = 1
            while dest_path.exists():
                stem = file_path.stem
                suffix = file_path.suffix
                dest_path = Path(processed_folder) / f"{stem}_{counter}{suffix}"
                counter += 1
            
            shutil.move(str(file_path), str(dest_path))
            logger.info(f"Moved file to processed: {dest_path}")
            return True
            
        except Exception as e:
            logger.warning(f"Attempt {attempt+1}: failed to move {file_path.name}: {e}")
            time.sleep(1)
    
    logger.error(f"All retries failed moving {file_path.name}")
    session_stats["errors"] += 1
    return False

def process_file(file_path, config):
    """Enhanced file processing with comprehensive validation"""
    logger.info(f"Processing file: {file_path.name}")
    
    # Wait for file stability
    if not wait_for_file_stability(file_path):
        logger.error(f"File not stable, skipping: {file_path.name}")
        session_stats["errors"] += 1
        return False

    # Read file with multiple attempts
    text = None
    for attempt in range(3):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
            break
        except Exception as e:
            logger.warning(f"Read attempt {attempt+1} failed for {file_path.name}: {e}")
            time.sleep(1)
    
    if not text:
        logger.error(f"Could not read {file_path.name} after 3 attempts")
        session_stats["errors"] += 1
        return False

    # Validate input text
    if len(text.strip()) < 100:
        logger.warning(f"File too short ({len(text)} chars), skipping: {file_path.name}")
        session_stats["errors"] += 1
        return False

    # Chunk the text
    sentence_limit = config.get("chunk_size", 100)
    chunks = chunk_text(text, sentence_limit)
    
    if not chunks:
        logger.error(f"No valid chunks created for {file_path.name}")
        session_stats["errors"] += 1
        return False

    # Prepare output
    timestamp = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    clean_base = Path(file_path.name).stem.replace(" ", "_")
    output_folder = config.get("output_dir", "output")
    chunk_files = []
    valid_chunks = 0

    # Write chunks with validation
    for i, chunk in enumerate(chunks):
        if validate_chunk_content(chunk):
            chunk_file = Path(output_folder) / f"{timestamp}_{clean_base}_chunk{i+1}.txt"
            try:
                os.makedirs(output_folder, exist_ok=True)
                with open(chunk_file, "w", encoding="utf-8") as cf:
                    cf.write(chunk)
                
                # Verify file was written correctly
                if os.path.getsize(chunk_file) > 0:
                    chunk_files.append(chunk_file)
                    valid_chunks += 1
                    logger.info(f"Created chunk: {chunk_file.name} ({len(chunk)} chars)")
                else:
                    logger.warning(f"Zero-byte chunk prevented: {chunk_file.name}")
                    session_stats["zero_byte_prevented"] += 1
                    os.remove(chunk_file)  # Clean up
                    
            except Exception as e:
                logger.error(f"Failed to write chunk {i+1} for {file_path.name}: {e}")
                session_stats["errors"] += 1
        else:
            logger.warning(f"Invalid chunk {i+1} skipped for {file_path.name}")

    session_stats["chunks_created"] += valid_chunks
    
    if not chunk_files:
        logger.warning(f"No valid chunks created for {file_path.name}")
        session_stats["errors"] += 1
        return False

    # Cloud copy
    cloud_dir = Path(config["cloud_repo_root"]) / f"{timestamp}_{clean_base}"
    cloud_success = False
    
    for attempt in range(3):
        if copy_to_cloud(chunk_files, cloud_dir):
            logger.info(f"Cloud sync successful: {cloud_dir}")
            cloud_success = True
            break
        logger.warning(f"Cloud sync attempt {attempt+1} failed")
        time.sleep(2)

    # Move to processed
    move_success = move_to_processed(file_path, config.get("archive_dir", "processed"))
    
    if move_success:
        session_stats["files_processed"] += 1
        logger.info(f"File processing complete: {file_path.name} â†’ {valid_chunks} chunks")
    
    return move_success

def log_session_stats():
    """Log session statistics"""
    logger.info("=== SESSION STATISTICS ===")
    for key, value in session_stats.items():
        logger.info(f"{key}: {value}")

def main():
    """Enhanced main loop with better error handling"""
    watch_folder = CONFIG.get("watch_folder", "C:/Users/carucci_r/Documents/chunker")
    os.makedirs(CONFIG.get("output_dir", "output"), exist_ok=True)
    os.makedirs(CONFIG.get("archive_dir", "processed"), exist_ok=True)

    logger.info(f"Enhanced watcher started - monitoring: {watch_folder}")
    logger.info(f"Target pattern: *_full_conversation.txt")
    
    processed_files = set()
    loop_count = 0
    
    while True:
        try:
            # Look for conversation files
            all_files = list(Path(watch_folder).glob("*_full_conversation.txt"))
            new_files = [f for f in all_files if f.name not in processed_files]
            
            if new_files:
                logger.info(f"Found {len(new_files)} new files to process")
                
            for file_path in new_files:
                try:
                    if process_file(file_path, CONFIG):
                        processed_files.add(file_path.name)
                        logger.info(f"Successfully processed: {file_path.name}")
                    else:
                        logger.error(f"Failed to process: {file_path.name}")
                except Exception as e:
                    logger.exception(f"Error processing {file_path.name}: {e}")
                    session_stats["errors"] += 1
            
            # Periodic status logging
            loop_count += 1
            if loop_count % 12 == 0:  # Every minute at 5s intervals
                log_session_stats()
            
            time.sleep(CONFIG.get("polling_interval", 5))
            
        except KeyboardInterrupt:
            logger.info("Watcher stopped by user")
            log_session_stats()
            break
        except Exception as e:
            logger.exception("Critical error in main loop")
            session_stats["errors"] += 1
            time.sleep(10)  # Longer wait on critical error

if __name__ == "__main__":
    main()
ChatGPT said:
No â€” you do not need to add that code block (if os.path.getsize(chunk_file) > 0:) again â€” it's already implemented correctly in your watcher_splitter.py script. âœ… Current Implementation Status
This portion of your script:

# Verify file was written correctly
if os.path.getsize(chunk_file) > 0:
    chunk_files.append(chunk_file)
    valid_chunks += 1
    logger.info(f"Created chunk: {chunk_file.name} ({len(chunk)} chars)")
else:
    logger.warning(f"Zero-byte chunk prevented: {chunk_file.name}")
    session_stats["zero_byte_prevented"] += 1
    os.remove(chunk_file)  # Clean up
Already does all of the following:

Verifies the chunk file was written and has content. Logs a warning if the chunk file is zero bytes. Deletes the zero-byte file immediately. Increments a counter for reporting (session_stats["zero_byte_prevented"]). ðŸ” Additional Safeguards Already Present
You also already:

Validate content before writing (validate_chunk_content). Log skipped chunks. Handle all I/O errors gracefully. ðŸŸ© You're Covered
The script already handles zero-byte chunk prevention as expected â€” no changes needed here. You're doing it right. Let me know if you'd like help enhancing the validation rules further (e.g., checking for meaningful language content, minimum keyword density, etc.). You said:
Microsoft Windows [Version 10.0.26200.5622]
(c) Microsoft Corporation. All rights reserved. C:\Users\carucci_r>cd C:\Users\carucci_r\Documents\chunker

C:\Users\carucci_r\Documents\chunker>powershell "Get-Content logs\watcher.log -Tail 20"
2025-06-27 21:58:18,021 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:20,022 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:22,023 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:24,025 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:26,026 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:28,027 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:30,028 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:32,029 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:34,030 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:36,031 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:38,032 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:40,033 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:42,034 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:44,035 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:46,036 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:48,043 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:50,044 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt not found, waiting...
2025-06-27 21:58:52,045 [WARNING] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt did not stabilize after 30 seconds
2025-06-27 21:58:52,045 [ERROR] File 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt did not stabilize - skipping
2025-06-27 21:58:52,045 [WARNING] \u26a0\ufe0f Processing completed with issues: 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt

C:\Users\carucci_r\Documents\chunker>dir output /o:d | findstr "06/27/25"
06/27/25  12:39            45,141 2025_06_27_12_39_53_Summons_MVA_part_1.txt
06/27/25  12:39            34,793 2025_06_27_12_39_53_Summons_MVA_part_2.txt
06/27/25  12:39            36,158 2025_06_27_12_39_53_Summons_MVA_part_3.txt
06/27/25  12:39            45,141 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_1.txt
06/27/25  12:39            36,526 2025_06_27_12_39_53_Summons_MVA_part_4.txt
06/27/25  12:39            34,793 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_2.txt
06/27/25  12:39            33,448 2025_06_27_12_39_53_Summons_MVA_part_5.txt
06/27/25  12:39            31,491 2025_06_27_12_39_53_Summons_MVA_part_6.txt
06/27/25  12:39            36,158 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_3.txt
06/27/25  12:39            34,792 2025_06_27_12_39_53_Summons_MVA_part_7.txt
06/27/25  12:39            36,526 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_4.txt
06/27/25  12:39            33,554 2025_06_27_12_39_53_Summons_MVA_part_8.txt
06/27/25  12:39             6,033 2025_06_27_12_39_53_Summons_MVA_part_9.txt
06/27/25  12:39            33,448 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_5.txt
06/27/25  12:39            31,491 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_6.txt
06/27/25  12:39            34,792 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_7.txt
06/27/25  12:39            33,554 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_8.txt
06/27/25  12:39             6,033 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_9.txt
06/27/25  12:39           291,936 full_conversation.txt
06/27/25  12:39               116 summary.md
06/27/25  12:39           291,936 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_full_conversation.txt
06/27/25  21:49               165 2025_06_27_21_49_01_working_test_chunk1.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk1.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk2.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk3.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk4.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk5.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk6.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk7.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk8.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk9.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk10.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk11.txt
06/27/25  21:57            22,716 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk1.txt
06/27/25  21:57            34,351 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk2.txt
06/27/25  21:57            60,245 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk3.txt
06/27/25  21:57            30,922 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk4.txt
06/27/25  21:57            28,915 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk5.txt
06/27/25  21:57            26,061 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk6.txt
06/27/25  21:57            39,155 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk7.txt
06/27/25  21:57            35,147 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk8.txt
06/27/25  21:57            40,129 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk9.txt
06/27/25  21:57            26,268 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk10.txt
06/27/25  21:57            38,514 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk11.txt
06/27/25  21:57            38,635 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk12.txt
06/27/25  21:57            23,796 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk13.txt
06/27/25  21:57            43,468 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk14.txt
06/27/25  21:57    <DIR>          . 06/27/25  21:57            31,628 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk15.txt
06/27/25  22:03    <DIR>          ..

C:\Users\carucci_r\Documents\chunker>dir output\*.txt | findstr " 0 "
06/27/25  12:39           291,936 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_full_conversation.txt
06/27/25  12:39            45,141 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_1.txt
06/27/25  12:39            34,793 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_2.txt
06/27/25  12:39            36,158 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_3.txt
06/27/25  12:39            36,526 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_4.txt
06/27/25  12:39            33,448 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_5.txt
06/27/25  12:39            31,491 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_6.txt
06/27/25  12:39            34,792 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_7.txt
06/27/25  12:39            33,554 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_8.txt
06/27/25  12:39             6,033 2025_06_27_12_39_53_Prompt_Builder_Python_Power_Query_Project_Summons_MVA_part_9.txt
06/27/25  12:39            45,141 2025_06_27_12_39_53_Summons_MVA_part_1.txt
06/27/25  12:39            34,793 2025_06_27_12_39_53_Summons_MVA_part_2.txt
06/27/25  12:39            36,158 2025_06_27_12_39_53_Summons_MVA_part_3.txt
06/27/25  12:39            36,526 2025_06_27_12_39_53_Summons_MVA_part_4.txt
06/27/25  12:39            33,448 2025_06_27_12_39_53_Summons_MVA_part_5.txt
06/27/25  12:39            31,491 2025_06_27_12_39_53_Summons_MVA_part_6.txt
06/27/25  12:39            34,792 2025_06_27_12_39_53_Summons_MVA_part_7.txt
06/27/25  12:39            33,554 2025_06_27_12_39_53_Summons_MVA_part_8.txt
06/27/25  12:39             6,033 2025_06_27_12_39_53_Summons_MVA_part_9.txt
06/27/25  21:49               165 2025_06_27_21_49_01_working_test_chunk1.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk1.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk10.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk11.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk2.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk3.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk4.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk5.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk6.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk7.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk8.txt
06/27/25  21:55                 0 2025_06_27_21_55_26_2025_06_27_17_08_32_policy_train_01_chunk9.txt
06/27/25  21:57            22,716 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk1.txt
06/27/25  21:57            26,268 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk10.txt
06/27/25  21:57            38,514 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk11.txt
06/27/25  21:57            38,635 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk12.txt
06/27/25  21:57            23,796 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk13.txt
06/27/25  21:57            43,468 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk14.txt
06/27/25  21:57            31,628 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk15.txt
06/27/25  21:57            34,351 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk2.txt
06/27/25  21:57            60,245 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk3.txt
06/27/25  21:57            30,922 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk4.txt
06/27/25  21:57            28,915 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk5.txt
06/27/25  21:57            26,061 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk6.txt
06/27/25  21:57            39,155 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk7.txt
06/27/25  21:57            35,147 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk8.txt
06/27/25  21:57            40,129 2025_06_27_21_57_53_2025_06_25_20_11_19_chatgpt_cad_rns_code_01a_chunk9.txt
06/27/25  12:39           291,936 full_conversation.txt
               0 Dir(s)  509,603,868,672 bytes free

C:\Users\carucci_r\Documents\chunker>dir processed /o:d
 Volume in drive C is OS
 Volume Serial Number is A263-CE95

 Directory of C:\Users\carucci_r\Documents\chunker\processed

06/25/25  20:12           519,561 2025_06_25_20_11_19_chatgpt_cad_rns_code_01a.txt
06/27/25  17:09           267,090 2025_06_27_17_08_32_policy_train_01.txt
06/27/25  21:34               153 test_file_now.txt
06/27/25  21:37                94 test_live.txt
06/27/25  21:48                97 working_test.txt
06/27/25  21:57    <DIR>          . 06/27/25  22:03    <DIR>          ..
               5 File(s)        786,995 bytes
               2 Dir(s)  509,603,930,112 bytes free

C:\Users\carucci_r\Documents\chunker>cd C:\Users\carucci_r\Documents\chunker

C:\Users\carucci_r\Documents\chunker>copy watcher_splitter.py watcher_splitter_backup.py
        1 file(s) copied. C:\Users\carucci_r\Documents\chunker># Check for zero-byte files first
'#' is not recognized as an internal or external command,
operable program or batch file.