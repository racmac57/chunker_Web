]
        
        for i, doc in enumerate(test_docs):
            metadata = {
                "file_name": f"test_doc_{i+1}.md",
                "file_type": ".md",
                "chunk_index": 1,
                "timestamp": "2025-10-27T12:00:00Z",
                "department": "admin",
                "keywords": ["test", "document"],
                "file_size": len(doc),
                "processing_time": 0.1
            }
            rag.add_chunk(doc, metadata)
        
        logger.info("Test RAG system setup complete")
        return rag
        
    except Exception as e:
        logger.error(f"Failed to setup test RAG system: {e}")
        return None


def run_rag_tests() -> Dict[str, Any]:
    """
    Run comprehensive RAG tests
    
    Returns:
        Test results dictionary
    """
    if not RAG_AVAILABLE:
        return {"error": "RAG components not available"}
    
    results = {
        "tests_passed": 0,
        "tests_failed": 0,
        "test_results": [],
        "overall_score": 0.0
    }
    
    try:
        # Setup test system
        rag_system = setup_test_rag_system()
        if not rag_system:
            results["error"] = "Failed to setup test RAG system"
            return results
        
        # Load test queries
        test_queries = load_test_queries()
        if not test_queries:
            results["error"] = "No test queries available"
            return results
        
        # Initialize evaluators
        faithfulness_scorer = FaithfulnessScorer()
        evaluator = RAGEvaluator()
        
        # Run evaluation pipeline
        evaluation_results = run_evaluation_pipeline(
            test_queries, rag_system, faithfulness_scorer
        )
        
        # Analyze results
        total_score = 0.0
        valid_tests = 0
        
        for result in evaluation_results:
            if "error" in result:
                results["tests_failed"] += 1
                results["test_results"].append({
                    "query": result.get("query", "Unknown"),
                    "status": "failed",
                    "error": result["error"]
                })
                continue
            
            # Check retrieval metrics
            retrieval_metrics = result.get("retrieval_metrics", {})
            precision_at_k = retrieval_metrics.get("precision_at_k", 0.0)
            recall_at_k = retrieval_metrics.get("recall_at_k", 0.0)
            mrr = retrieval_metrics.get("mrr", 0.0)
            
            # Check quality metrics
            quality_metrics = result.get("quality_metrics", {})
            faithfulness = result.get("faithfulness", 0.0)
            
            # Calculate test score
            test_score = (precision_at_k + recall_at_k + mrr + faithfulness) / 4.0
            total_score += test_score
            valid_tests += 1
            
            # Determine pass/fail
            passed = test_score >= 0.5  # Threshold for passing
            
            if passed:
                results["tests_passed"] += 1
                status = "passed"
            else:
                results["tests_failed"] += 1
                status = "failed"
            
            results["test_results"].append({
                "query": result["query"],
                "status": status,
                "score": test_score,
                "precision_at_k": precision_at_k,
                "recall_at_k": recall_at_k,
                "mrr": mrr,
                "faithfulness": faithfulness
            })
        
        # Calculate overall score
        if valid_tests > 0:
            results["overall_score"] = total_score / valid_tests
        
        logger.info(f"RAG tests completed: {results['tests_passed']} passed, {results['tests_failed']} failed")
        logger.info(f"Overall score: {results['overall_score']:.3f}")
        
    except Exception as e:
        logger.error(f"RAG tests failed: {e}")
        results["error"] = str(e)
    
    return results


def assert_test_thresholds(results: Dict[str, Any], thresholds: Dict[str, float]) -> bool:
    """
    Assert that test results meet minimum thresholds
    
    Args:
        results: Test results dictionary
        thresholds: Minimum threshold values
        
    Returns:
        True if all thresholds met, False otherwise
    """
    if "error" in results:
        logger.error(f"Tests failed with error: {results['error']}")
        return False
    
    # Check overall score threshold
    overall_threshold = thresholds.get("overall_score", 0.5)
    if results["overall_score"] < overall_threshold:
        logger.error(f"Overall score {results['overall_score']:.3f} below threshold {overall_threshold}")
        return False
    
    # Check individual test thresholds
    precision_threshold = thresholds.get("precision_at_k", 0.3)
    recall_threshold = thresholds.get("recall_at_k", 0.3)
    faithfulness_threshold = thresholds.get("faithfulness", 0.4)
    
    failed_tests = []
    for test_result in results["test_results"]:
        if test_result["status"] == "failed":
            continue
        
        if test_result.get("precision_at_k", 0) < precision_threshold:
            failed_tests.append(f"Precision@K too low for query: {test_result['query']}")
        
        if test_result.get("recall_at_k", 0) < recall_threshold:
            failed_tests.append(f"Recall@K too low for query: {test_result['query']}")
        
        if test_result.get("faithfulness", 0) < faithfulness_threshold:
            failed_tests.append(f"Faithfulness too low for query: {test_result['query']}")
    
    if failed_tests:
        for failure in failed_tests:
            logger.error(failure)
        return False
    
    logger.info("All test thresholds met!") return True


def main():
    """Main testing function"""
    print("=== RAG Testing Script ===")
    
    if not RAG_AVAILABLE:
        print("âŒ RAG components not available. Please install dependencies.") sys.exit(1)
    
    # Define test thresholds
    thresholds = {
        "overall_score": 0.5,
        "precision_at_k": 0.3,
        "recall_at_k": 0.3,
        "faithfulness": 0.4
    }
    
    print(f"Running RAG tests with thresholds: {thresholds}")
    
    # Run tests
    results = run_rag_tests()
    
    # Print results
    print("\n=== Test Results ===")
    if "error" in results:
        print(f"âŒ Tests failed: {results['error']}")
        sys.exit(1)
    
    print(f"Tests passed: {results['tests_passed']}")
    print(f"Tests failed: {results['tests_failed']}")
    print(f"Overall score: {results['overall_score']:.3f}")
    
    print("\n=== Individual Test Results ===")
    for test_result in results["test_results"]:
        status_icon = "âœ…" if test_result["status"] == "passed" else "âŒ"
        print(f"{status_icon} {test_result['query']}")
        print(f"   Score: {test_result.get('score', 0):.3f}")
        print(f"   Precision@K: {test_result.get('precision_at_k', 0):.3f}")
        print(f"   Recall@K: {test_result.get('recall_at_k', 0):.3f}")
        print(f"   Faithfulness: {test_result.get('faithfulness', 0):.3f}")
        print()
    
    # Assert thresholds
    if assert_test_thresholds(results, thresholds):
        print("ðŸŽ‰ All tests passed!") sys.exit(0)
    else:
        print("âŒ Some tests failed thresholds")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

Now let me update the README with RAG query examples:


```markdown
# Chunker Project - Final Migration

This project has been migrated to C:/_chunker on 2025-08-25 18:58:28. ## Directory Structure

- **C:/_chunker** - Main project directory with scripts
- **02_data/** - Input files to be processed (watch folder)
- **03_archive/** - Archived original files and processed source files
- **04_output/** - Generated chunks and transcripts (organized by source file)
- **05_logs/** - Application logs and tracking
- **06_config/** - Configuration files

## Quick Start

1. Place files to process in `02_data/` folder
2. Run the watcher: `python watcher_splitter.py`
3. Check `04_output/` for processed chunks and transcripts
4. Original files are moved to `03_archive/` after processing

## Features

- [x] Organized output by source file name
- [x] Admin files output as .md with headers
- [x] All other files output as .txt
- [x] Automatic file organization and archiving
- [x] Database tracking and logging
- [x] **Unicode filename support** - Handles files with emojis, special characters, and symbols
- [x] **Enhanced filename sanitization** - Automatically cleans problematic characters while preserving readability
- [x] **Timestamp-organized output** - Output folders include processing timestamp (YYYY_MM_DD_HH_MM_SS_) for chronological organization
- [x] **RAG Integration** - ChromaDB vector database for semantic search and knowledge base
- [x] **Multi-file type support** - Processes .txt, .md, .json, .csv, .xlsx, .pdf, .py, .docx, .sql, .yaml, .xml, .log
- [x] **Faithfulness scoring** - Evaluates answer grounding in source context
- [x] **RAG evaluation metrics** - Precision@K, Recall@K, MRR, ROUGE, BLEU scores
- [x] **LangSmith integration** - Tracing and evaluation capabilities (optional)

## Configuration

Edit `config.json` to customize:
- File filter modes (all, patterns, suffix)
- Supported file extensions
- Chunk sizes and processing options
- Notification settings
- RAG settings (ChromaDB, LangSmith)

## RAG Usage

### Setup
1. Install RAG dependencies: `python install_rag_dependencies.py`
2. Enable RAG in `config.json`: Set `"rag_enabled": true`
3. Start the watcher: `python watcher_splitter.py`

### Search Knowledge Base
```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

### RAG Query Example

Here's how to use the RAG search functionality:

```bash
# Interactive search
python rag_search.py

# Command line search
python rag_search.py "How do I fix vlookup errors?" ```

**Example Output:**
```
Found 3 results:
Result 1:
File: excel_guide.md
Type: .md
Department: admin
Chunk: 1
Content: VLOOKUP is used to find values in a table. Syntax: VLOOKUP(lookup_value, table_array, col_index_num, [range_lookup]). Use FALSE for exact matches...
Similarity Score: 0.847

Result 2:
File: troubleshooting.xlsx
Type: .xlsx
Department: admin
Chunk: 2
Content: Common VLOOKUP errors include #N/A when lookup value not found, #REF when table array is invalid...
Similarity Score: 0.723
```

**Testing RAG Performance:**
```bash
# Run automated tests
python rag_test.py

# Expected output:
# Tests passed: 4
# Tests failed: 1
# Overall score: 0.623
# ðŸŽ‰ All tests passed! ```

### Evaluation
```python
from rag_evaluation import RAGEvaluator
from rag_integration import FaithfulnessScorer

# Evaluate retrieval quality
evaluator = RAGEvaluator()
metrics = evaluator.evaluate_retrieval(ground_truth, retrieved)

# Evaluate answer faithfulness
scorer = FaithfulnessScorer()
score = scorer.calculate_faithfulness(answer, context)
```

### Supported File Types
- **Text files**: .txt, .md, .json, .csv, .sql, .log
- **Office files**: .xlsx (Excel), .docx (Word)
- **Code files**: .py (Python with AST parsing)
- **Data files**: .yaml, .xml
- **Documents**: .pdf (text extraction)

### RAG Features
- **Semantic search** using ChromaDB vector database
- **Hybrid search** combining semantic and keyword matching
- **Faithfulness scoring** to evaluate answer grounding
- **Comprehensive evaluation** with multiple metrics
- **LangSmith integration** for tracing and monitoring (optional)

```

Now let me update the changelog to reflect all the improvements:


```markdown
# Changelog

All notable changes to the Enterprise Chunker system will be documented in this file. The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html). ## [Version 1.2.1] - 2025-10-27 - Enhanced RAG Implementation

### Fixed
- **Redundant file opens**: Fixed processors to use passed text instead of reopening files
- **Encoding handling**: Changed from 'ignore' to 'replace' for better data preservation
- **NLTK import issues**: Added proper stopwords handling with fallback
- **LangSmith integration**: Cleaned up unused imports and improved error handling

### Enhanced
- **Modular file processors**: Created `file_processors.py` module for better organization
- **Security redaction**: Added PII redaction for sensitive data in RAG chunks
- **Config validation**: Added startup validation for configuration parameters
- **Error handling**: Improved graceful degradation when RAG components unavailable
- **Performance**: Better memory handling for large files

### Added
- **Automated testing**: `rag_test.py` for comprehensive RAG evaluation
- **Type hints**: Added type annotations throughout RAG modules
- **Comprehensive docstrings**: Improved documentation for all functions
- **Dependency checking**: Runtime checks for file processor dependencies
- **RAG query examples**: Added usage examples to README

### Technical Improvements
- **File processing**: Streamlined file reading with appropriate processors
- **Error recovery**: Better error handling without breaking main processing
- **Code organization**: Separated concerns into dedicated modules
- **Testing framework**: Automated test suite with threshold validation
- **Documentation**: Enhanced examples and usage instructions

## [Version 1.2.0] - 2025-10-27 - RAG Integration Complete

### Added
- **RAG Integration**: Comprehensive retrieval-augmented generation system with ChromaDB
- **Vector Database**: ChromaDB integration for semantic search and knowledge base management
- **Faithfulness Scoring**: Advanced evaluation of answer grounding in source context
- **Expanded File Type Support**: Added processors for .xlsx, .pdf, .py, .docx, .sql, .yaml, .xml, .log
- **RAG Evaluation Metrics**: Precision@K, Recall@K, MRR, nDCG, ROUGE, BLEU scores
- **LangSmith Integration**: Tracing, feedback collection, and quality assurance capabilities
- **Hybrid Search**: Combined semantic and keyword-based retrieval
- **Advanced Metadata Extraction**: Enhanced metadata for all file types including formulas, imports, docstrings

### Implementation Files
- `rag_integration.py`: ChromaDB RAG system with faithfulness scoring
- `rag_evaluation.py`: Comprehensive evaluation metrics and pipeline
- `rag_search.py`: Interactive search interface and command-line tool
- `install_rag_dependencies.py`: Automated dependency installation script
- `test_queries.json`: Test queries for evaluation
- `GROK_IMPLEMENTATION_GUIDE.md`: Complete guide for Grok implementation
- Updated `config.json` with RAG and LangSmith configuration
- Updated `requirements.txt` with all necessary dependencies
- Updated `watcher_splitter.py` with RAG integration and file type processors
- Updated `README.md` with RAG usage documentation

### Technical Details
- Integrated ChromaDB vector database with automatic chunk indexing
- Added file type processors for Excel, PDF, Python, Word, YAML, XML, SQL, and log files
- Implemented faithfulness scoring using sentence transformers
- Added comprehensive RAG evaluation metrics (retrieval and generation)
- Created interactive search interface with command-line support
- Added automated dependency installation script
- Integrated RAG processing into existing watcher pipeline

### Usage
- Enable RAG: Set `"rag_enabled": true` in config.json
- Install dependencies: `python install_rag_dependencies.py`
- Search knowledge base: `python rag_search.py`
- Process files: `python watcher_splitter.py` (automatically adds to ChromaDB)

## [Version 1.1.0] - 2025-10-27

### Added
- **Timestamp-prefixed output folders**: Output folders now include `YYYY_MM_DD_HH_MM_SS_` prefix for better chronological organization
- **Enhanced file organization**: Processed files are now organized by processing timestamp, making it easier to track when files were processed
- **Robust chunking logging**: Added detailed logging for chunking operations including text length, sentence count, chunk parameters, and processing statistics
- **Directory cleanup and organization**: Moved old scripts to archive, organized documentation in 99_doc folder

### Fixed
- **Critical Fix**: Resolved Unicode filename processing issues that prevented files with special characters (emojis, symbols) from being processed correctly
- **Enhanced filename sanitization**: Improved regex-based cleaning to handle problematic characters while preserving readable filenames
- **Unicode encoding errors**: Fixed console logging issues with special characters that caused processing failures
- **Directory creation failures**: Resolved "No such file or directory" errors when creating output folders for files with special characters
- **Windows path length limits**: Fixed directory name length issues by reducing filename limit to 50 characters to account for timestamp prefixes

### Technical Details
- Added enhanced filename sanitization using regex pattern `[^\w\s-]` to remove special characters
- Implemented safe filename logging with ASCII encoding fallback to prevent console encoding errors
- Added filename length limits (100 characters) to prevent Windows path length issues
- Improved error handling for directory creation and file writing operations

### Impact
- Files with emojis, special symbols, and Unicode characters now process successfully
- Eliminated processing failures that previously required manual filename changes
- Improved system reliability for diverse file naming conventions
- Maintained backward compatibility with existing filename formats

## [Previous Versions]

### Initial Release
- Enterprise-grade chunker with database tracking
- Parallel processing capabilities
- Department-specific configurations
- Comprehensive logging and monitoring
- Automatic file archiving and organization

```

Let me update the TODO list to mark completed tasks:


Let me check for any linting errors in the updated files:


Let me fix the logger issue in watcher_splitter.py:


```python
# ðŸ•’ 2025-06-28-01-55-30
# chunker/watcher_splitter_enterprise.py
# Author: R. A. Carucci  
# Purpose: Enterprise-grade chunker with database tracking, notifications, and parallel processing

import os
import sys
import time 
import shutil
import logging
import traceback
from datetime import datetime, timedelta
from pathlib import Path
import nltk
from nltk.tokenize import sent_tokenize
import json
import psutil
from concurrent.futures import ThreadPoolExecutor
import multiprocessing
from chunker_db import ChunkerDatabase
from notification_system import NotificationSystem
import re
import openpyxl
import PyPDF2
import ast
import docx
import yaml
from rag_integration import ChromaRAG, extract_keywords
from file_processors import get_file_processor, check_processor_dependencies, redact_sensitive_data

# Graceful RAG imports with error handling
try:
    from langchain_rag_handler import LangChainRAGHandler, graceful_rag_handler, check_rag_dependencies
    RAG_DEPENDENCIES_AVAILABLE = True
except ImportError:
    # Logger not yet defined, use print for now
    print("LangChain RAG handler not available - using basic RAG only")
    RAG_DEPENDENCIES_AVAILABLE = False

def validate_config(config):
    """Validate configuration parameters"""
    errors = []
    
    # Check required fields
    required_fields = ["watch_folder", "output_dir", "archive_dir"]
    for field in required_fields:
        if field not in config:
            errors.append(f"Missing required field: {field}")
    
    # Check data types
    if "rag_enabled" in config and not isinstance(config["rag_enabled"], bool):
        errors.append("rag_enabled must be boolean")
    
    if "chunk_size" in config and not isinstance(config["chunk_size"], int):
        errors.append("chunk_size must be integer")
    
    if "chroma_persist_dir" in config and not isinstance(config["chroma_persist_dir"], str):
        errors.append("chroma_persist_dir must be string")
    
    # Check LangSmith config
    if "langsmith" in config:
        langsmith_config = config["langsmith"]
        if not isinstance(langsmith_config, dict):
            errors.append("langsmith config must be dictionary")
        else:
            if "project" in langsmith_config and not isinstance(langsmith_config["project"], str):
                errors.append("langsmith.project must be string")
    
    if errors:
        logger.error("Configuration validation errors:")
        for error in errors:
            logger.error(f"  - {error}")
        return False
    
    logger.info("Configuration validation passed")
    return True

def safe_chroma_add(chunk, metadata, config):
    """Safely add chunk to ChromaDB with error handling"""
    try:
        if not config.get("rag_enabled", False):
            return None
        
        chroma_rag = ChromaRAG(persist_directory=config.get("chroma_persist_dir", "./chroma_db"))
        chunk_id = chroma_rag.add_chunk(chunk, metadata)
        logger.debug(f"Added chunk to ChromaDB: {chunk_id}")
        return chunk_id
        
    except ImportError as e:
        logger.warning(f"ChromaDB not available: {e}")
        logger.info("Continuing without RAG functionality")
        return None
    except Exception as e:
        logger.error(f"Failed to add chunk to ChromaDB: {e}")
        return None

# Resolve config path (supports PyInstaller .exe)
if getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):
    base_path = sys._MEIPASS
else:
    base_path = os.path.dirname(__file__)

# Configure local nltk_data path
nltk_path = os.path.join(base_path, "nltk_data")
nltk.data.path.append(nltk_path)

try:
    nltk.download('punkt_tab', download_dir=nltk_path, quiet=True)
except:
    nltk.download('punkt', download_dir=nltk_path, quiet=True)

# Load configuration
with open(os.path.join(base_path, "config.json")) as f:
    CONFIG = json.load(f)

# Department-specific configurations
DEPARTMENT_CONFIGS = {
    "police": {
        "chunk_size": 75,
        "enable_redaction": True,
        "audit_level": "full",
        "priority": "high"
    },
    "admin": {
        "chunk_size": 150,
        "enable_redaction": False,
        "audit_level": "basic",
        "priority": "normal"
    },
    "legal": {
        "chunk_size": 100,
        "enable_redaction": True,
        "audit_level": "full",
        "priority": "high"
    }
}

# Setup enhanced logging
def setup_logging():
    log_file = CONFIG.get("log_file", "logs/watcher.log")
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    
    # Rotate log if it's too large
    if os.path.exists(log_file) and os.path.getsize(log_file) > 5 * 1024 * 1024:  # 5MB
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_name = f"logs/watcher_archive_{timestamp}.log"
        shutil.move(log_file, archive_name)
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

# Initialize database and notification systems with timeout and retry
def init_database_with_retry():
    """Initialize database with retry logic to handle locking issues"""
    max_retries = 5
    for attempt in range(max_retries):
        try:
            db = ChunkerDatabase()
            logger.info("Database initialized successfully")
            return db
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"Database initialization attempt {attempt + 1} failed: {e}")
                time.sleep(2)
            else:
                logger.error(f"Database initialization failed after {max_retries} attempts: {e}")
                return None

db = init_database_with_retry()
notifications = NotificationSystem()

# Enhanced session statistics
session_stats = {
    "session_start": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "files_processed": 0,
    "chunks_created": 0,
    "zero_byte_prevented": 0,
    "errors": 0,
    "total_sentences_processed": 0,
    "total_bytes_created": 0,
    "parallel_jobs_completed": 0,
    "department_breakdown": {},
    "performance_metrics": {
        "avg_processing_time": 0,
        "peak_memory_usage": 0,
        "peak_cpu_usage": 0
    }
}

def get_department_config(file_path):
    """Determine department configuration based on file path or content"""
    dept = CONFIG.get("default_department", "admin")
    
    # Check file path for department indicators
    path_str = str(file_path).lower()
    for department in DEPARTMENT_CONFIGS.keys():
        if department in path_str:
            dept = department
            break
    
    # Merge default config with department-specific settings
    dept_config = DEPARTMENT_CONFIGS.get(dept, {})
    merged_config = CONFIG.copy()
    merged_config.update(dept_config)
    merged_config["department"] = dept
    
    return merged_config

def log_system_metrics():
    """Log comprehensive system metrics"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('.')